{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0748d01",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"./images/PallenceAI-Final.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccee792",
   "metadata": {},
   "source": [
    "# Keras Basics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162adc49",
   "metadata": {},
   "source": [
    "## Import needed libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a9babbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Python packages for data wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Tensorflow & Keras related packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e996f7",
   "metadata": {},
   "source": [
    "**Keras Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b9137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything in Keras is either a layer or something that interacts with Layer.\n",
    "# A layer is an object that represents some state (weights) and also some computation (forward pass)\n",
    "# Keras layer class takes care of automatic shape inference, when creating layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a75e26",
   "metadata": {},
   "source": [
    "**Keras Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e1727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A deep Learning model in keras is simply a graph of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b09e4c",
   "metadata": {},
   "source": [
    "<img src=\"./images/DL-Intuition3.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7a09a3",
   "metadata": {},
   "source": [
    "**Different Ways to build Keras Deep Learning Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cd7f8e",
   "metadata": {},
   "source": [
    "1. Sequential API\n",
    "2. Functional API\n",
    "3. Model Subclassing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a59684d",
   "metadata": {},
   "source": [
    "<img src=\"./images/keras2.png\" width = \"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for the first Project: Model trained on Fashion_MNIST to detect 10 different classes of objects.\n",
    "## Preprocess or prepare the data\n",
    "# #------------------------------\n",
    "# train_images = train_images.reshape((60000, 28 * 28)) # Reshape each image from a 28 x 28 grayscale pixel values to 784 = 28*28\n",
    "# train_images = train_images.astype(\"float32\") / 255 # Convert into a float32 with values scaled between [0,1] instead of [0,255]\n",
    "# test_images = test_images.reshape((10000, 28 * 28)) # Reshape each image from a 28 x 28 grayscale pixel values to 784 = 28*28\n",
    "# test_images = test_images.astype(\"float32\") / 255 # Convert into a float32 with values scaled between [0,1] instead of [0,255]\n",
    "\n",
    "# #Build Neural Network Model Architecture\n",
    "# model = keras.Sequential() # Start building a sequential keras model\n",
    "# model.add(layers.Dense(512,activation='relu')) # Add first layer with 512 Hidden Units, and use Relu for nonlinear activation\n",
    "# model.add(layers.Dense(10,activation = \"softmax\")) # Last output layer which will be softmax classification.\n",
    "\n",
    "# #Compile the Model\n",
    "# model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "\n",
    "# #Fit or train the Deep Learning Model\n",
    "# model.fit(train_images, train_labels, epochs = 5, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e8aba7",
   "metadata": {},
   "source": [
    "### Sequential Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e7e2a",
   "metadata": {},
   "source": [
    "**You can build the Sequential model either way shown below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "627f1db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential Model\n",
    "model = keras.Sequential([layers.Dense(512, activation = \"relu\"),\n",
    "                          layers.Dense(10,activation = \"softmax\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a936e6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same thing as above. Add each layer incrementally instead of passing as a list\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(512, activation = \"relu\")) # we create a Hidden dense layer with 512 hidden units. Apply Relu activation\n",
    "model.add(layers.Dense(10, activation = \"softmax\")) # We create final output layer with 10 units. Apply softmax activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe92ed61",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"./images/DL-Intuition3.png\" width=\"300\">\n",
    "\n",
    "<img style = \"float: right;\" src=\"./images/forward_prop_equations.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f236cf2",
   "metadata": {},
   "source": [
    "**Lets look at the model summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed9e41dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Minimal\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mValueError\u001b[0m\u001b[1;31m:\u001b[0m This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.\n"
     ]
    }
   ],
   "source": [
    "%xmode Minimal\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f36fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error because model doesnt know the input shape yet. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9542e12b",
   "metadata": {},
   "source": [
    "**How to pass on the input shape?**\n",
    "1. Use the build method to give input shape\n",
    "2. Give the input ahead of time in the beginning as ur building the model\n",
    "3. Directly call the model on a batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27445b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1. We can use Build method of model to give an input shape \n",
    "model.build(input_shape=(None,784,)) # Defining the input shape X\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "902d5c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2. or give the input shape ahead of time before defining other layers\n",
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape = (784,)))\n",
    "model.add(layers.Dense(512, activation = \"relu\")) # we create a Hidden dense layer with 512 hidden units. Apply Relu activation\n",
    "model.add(layers.Dense(10, activation = \"softmax\")) # We create final output layer with 10 units. Apply softmax activation\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b6f7251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or if you want to define Sequential API by passing all layers as list\n",
    "\n",
    "# model = keras.Sequential([keras.Input(shape = (784,)), layers.Dense(512, activation = \"relu\"),\n",
    "#                           layers.Dense(10,activation = \"softmax\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7745349",
   "metadata": {},
   "source": [
    "**Giving names to each layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcca8737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also give names to pretty much anything in keras\n",
    "\n",
    "model = keras.Sequential(name=\"Sequential_model\")\n",
    "model.add(keras.Input(shape=(784,), name=\"input_layer\")) \n",
    "model.add(layers.Dense(512, activation=\"relu\", name=\"hidden_layer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3465d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer (Dense)        (None, 512)               401920    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 401,920\n",
      "Trainable params: 401,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # so far we just added one Hidden dense layer, after defining the input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce73848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer (Dense)        (None, 512)               401920    \n",
      "                                                                 \n",
      " final_output_layer (Dense)  (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Now we can keep adding to the model by adding another layer\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"final_output_layer\")) # lets say the output layer\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f32d73",
   "metadata": {},
   "source": [
    "### Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c392615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Model architecture is very simple in that it just had one input, one hidden, \n",
    "#...one output layer all connected sequentially\n",
    "# Hence sequential API worked pretty well for it.  \n",
    "\n",
    "# Sequential API\n",
    "#-------------------\n",
    "# model = keras.Sequential() # Start building a sequential keras model\n",
    "# model.add(keras.Input(shape=(784,)))\n",
    "# model.add(layers.Dense(512,activation='relu')) # Add first layer with 512 Hidden Units, and use Relu for nonlinear activation\n",
    "# model.add(layers.Dense(10,activation = \"softmax\")) # Last output layer which will be softmax classification.\n",
    "\n",
    "#But as we can see below, we can build same model with Functional API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "529e852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API model is an explicit graph data struture\n",
    "# Lets create the same 2 layer (hidden layer and output layer) neural network using functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d2a1f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Functional_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 784)]             0         \n",
      "                                                                 \n",
      " hidden_layer (Dense)        (None, 512)               401920    \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X = keras.Input(shape=(784,), name = \"input_layer\") # Inputs: Again this is just a symbolic tensor.\n",
    "\n",
    "A = layers.Dense(512,activation=\"relu\", name=\"hidden_layer\")(X) # Hidden layer output\n",
    "\n",
    "Ypred = layers.Dense(10,activation=\"softmax\", name=\"output_layer\")(A) # Final model prediction Ypred\n",
    "\n",
    "model = keras.Model(inputs=X,outputs = Ypred, name=\"Functional_model\")\n",
    "\n",
    "model.summary() # As u can see, its exact same model as before with Sequential API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ae09b",
   "metadata": {},
   "source": [
    "**Then why do we need Functional API?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6493317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But real power of functional API through its advantages\n",
    "# 1. Facilitates multi-input, multi output problems\n",
    "# 2. Visualize the model architecture and see the layer connectivity very easily for complex architectures\n",
    "# Reuse individual layers in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "056dd50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d9a884",
   "metadata": {},
   "source": [
    "**Weights (or Parameters)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65598cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets look at the weights of each layer. \n",
    "#...We have 2 layers: 1 hidden dense layer, and the final output dense layer\n",
    "\n",
    "len(model.weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92d43158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these weights are stored as a list. [W1,B1,W2,B2]\n",
    "\n",
    "# W1, B1 are used to compute hidden dense layer output \n",
    "# W2, B2 are used to compute final output Ypred\n",
    "\n",
    "#lets see the shapes & values of each of these weights in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274cb281",
   "metadata": {},
   "source": [
    "<img src=\"./images/weights.png\" width=\"500\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6dcfa0",
   "metadata": {},
   "source": [
    "**Lets look at each of the model layer we have defined above**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947cf224",
   "metadata": {},
   "source": [
    "**Hidden layer (with 512 hidden Units)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6425c574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 1st set of weights W1 is: (784, 512)\n"
     ]
    }
   ],
   "source": [
    "W1 = model.weights[0]\n",
    "print (f'Shape of 1st set of weights W1 is: {W1.shape}')\n",
    "# Shape of W1 (weights that are used to compute hidden dense layer (512 units) output \n",
    "#...using input pixels (784 pixels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b7bbe2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape B1 is: (512,)\n"
     ]
    }
   ],
   "source": [
    "B1 = model.weights[1]\n",
    "print (f'Shape B1 is: {B1.shape}')\n",
    "# Shape of B1 (Bias term used to compute hidden dense layer (512 units) output \n",
    "#...using input pixels (784 pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec14f640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters used to calculate hidden layer output: 401920\n"
     ]
    }
   ],
   "source": [
    "number_paramters_hiddenlayer = 784*512+512\n",
    "print (f\"Parameters used to calculate hidden layer output: {number_paramters_hiddenlayer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "415df96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'hidden_layer/kernel:0' shape=(784, 512) dtype=float32, numpy=\n",
       "array([[-0.04396496,  0.02883952, -0.06415268, ...,  0.05102568,\n",
       "        -0.0499161 , -0.01585603],\n",
       "       [ 0.02271894, -0.02996248, -0.06727785, ...,  0.00917599,\n",
       "         0.02523789,  0.01911623],\n",
       "       [ 0.0042187 ,  0.0150923 , -0.06771124, ...,  0.05676419,\n",
       "         0.06125471, -0.044574  ],\n",
       "       ...,\n",
       "       [ 0.03151403,  0.01277095,  0.05599069, ..., -0.00991369,\n",
       "        -0.05932115, -0.00486603],\n",
       "       [-0.05813292,  0.00547113,  0.0649658 , ...,  0.00298259,\n",
       "         0.05085603,  0.01976623],\n",
       "       [ 0.01244407,  0.04208975,  0.00163489, ..., -0.05938166,\n",
       "        -0.0281752 , -0.06342011]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 # randomly initialized weights for W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "473b2411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'hidden_layer/bias:0' shape=(512,) dtype=float32, numpy=\n",
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B1 # randomly initialized weights for B1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3781b5a",
   "metadata": {},
   "source": [
    "**Final Output layer (with 10 units: Ypred)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fad1e49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 1st set of weights W2 is: (512, 10)\n"
     ]
    }
   ],
   "source": [
    "W2 = model.weights[2]\n",
    "print (f'Shape of 1st set of weights W2 is: {W2.shape}')\n",
    "\n",
    "# Shape of W2 (weights that are used to compute final output layer (10 units) from hidden units (512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f495396e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of B2 is: (10,)\n"
     ]
    }
   ],
   "source": [
    "B2 = model.weights[3]\n",
    "print (f'Shape of B2 is: {B2.shape}')\n",
    "# Shape of B2 (bias term used to compute final output layer (10 units) from hidden units (512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ae4677d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters used to calculate final output layer: 5130\n"
     ]
    }
   ],
   "source": [
    "number_paramters_l2 = 512*10+10\n",
    "print (f\"Parameters used to calculate final output layer: {number_paramters_l2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "444d35cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'output_layer/kernel:0' shape=(512, 10) dtype=float32, numpy=\n",
       "array([[ 0.10144415,  0.01401188, -0.09567635, ..., -0.07537238,\n",
       "         0.03284854,  0.10084144],\n",
       "       [ 0.04839655,  0.062588  , -0.0246714 , ..., -0.05991806,\n",
       "        -0.02921262, -0.0195324 ],\n",
       "       [-0.09804771, -0.05455118,  0.04508341, ...,  0.03604815,\n",
       "        -0.02147697, -0.04802565],\n",
       "       ...,\n",
       "       [ 0.0639637 , -0.04840122, -0.01647158, ..., -0.0809636 ,\n",
       "         0.03570101,  0.01957714],\n",
       "       [-0.09009699,  0.09506776,  0.10449318, ..., -0.08751442,\n",
       "        -0.01486642,  0.04280017],\n",
       "       [ 0.08087457,  0.00895144, -0.0496891 , ..., -0.03436953,\n",
       "        -0.10082413,  0.07267693]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2 # Randomly intialized weights for W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57b4680f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'output_layer/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B2  # Randomly intialized weights for B2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9907de",
   "metadata": {},
   "source": [
    "### Lets train the model on the Fashion_MNIST dataset  but now with Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9fe6de",
   "metadata": {},
   "source": [
    "**Load Data Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec5deab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(train_images, train_labels),(test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98281be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4f5198f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42843f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f7c0f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels # train labels are represented as integers\n",
    "\n",
    "# if we keep them as integers then we have to choose sparse_categorical_crossentropy loss\n",
    "# if we convert them into one-hot vectors we have to choose categorical_cross_entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493fb80e",
   "metadata": {},
   "source": [
    "**Preprocess Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e03480f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess data\n",
    "train_images = train_images.reshape((60000,28*28)).astype(\"float32\")/255\n",
    "test_images = test_images.reshape((10000,28*28)).astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4989808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca4735f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoded vectors if needed and choose categorical_crossentropy loss\n",
    "\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes=10)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8eca44bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0130b312",
   "metadata": {},
   "source": [
    "**Build the Neural Architecture with Functional API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "299e4d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the Neuralnetwork Architecture\n",
    "# lets use a function that defines the model architecture. so that we can use it as often as we want.\n",
    "def model_fashion_mnist():\n",
    "    X = keras.Input(shape=(784,), name = \"input\") # Inputs: Again this is just a symbolic tensor. \n",
    "    A = keras.layers.Dense(512,activation=\"relu\", name=\"hidden_layer\")(X) # Hidden layer output\n",
    "    Ypred = keras.layers.Dense(10,activation=\"softmax\", name=\"output_layer\")(A) # Final model prediction Ypred\n",
    "    \n",
    "    model = keras.Model(inputs=X,outputs = Ypred)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da2a7fb",
   "metadata": {},
   "source": [
    "<img src=\"./images/DL-Intuition3.png\" width=\"500\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d31105d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 784)]             0         \n",
      "                                                                 \n",
      " hidden_layer (Dense)        (None, 512)               401920    \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_fashion_mnist()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec25514d",
   "metadata": {},
   "source": [
    "**Compile the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d03cb0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model = model_fashion_mnist()\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "\n",
    "# choose loss = categorical_crossentropy if labels are one-hot vectors\n",
    "# choose loss = sparse_categorical_crossentropy if labels are integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0222fb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer, losses and metric above have been given as strings, \n",
    "# These strings are nothing but shortcuts which get converted to python objects \n",
    "#..can and be specified as shown below\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(), \n",
    "              loss=keras.losses.CategoricalCrossentropy(),\n",
    "              metrics = [keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130d5831",
   "metadata": {},
   "source": [
    "**Train the model on the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9de2c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 5s 6ms/step - loss: 0.5563 - categorical_accuracy: 0.8033\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.3842 - categorical_accuracy: 0.8583\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.3379 - categorical_accuracy: 0.8762\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3124 - categorical_accuracy: 0.8838\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2937 - categorical_accuracy: 0.8927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14d1d669a60>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "model.fit(train_images, train_labels, epochs = 5, batch_size = 128)\n",
    "\n",
    "# in the above we are providing X (input),Y (targets or labels) into the fit method, \n",
    "#...by sperating training data into X & y.\n",
    "\n",
    "# later we will see with some custom data generators and/or tensorflow based tf.data.Dataset object\n",
    "#...we can pass just the training data direcctly without seperating into X & Y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7e7cad",
   "metadata": {},
   "source": [
    "### We can enhance the capabilities for training the model in keras in many ways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f351ed",
   "metadata": {},
   "source": [
    "**Train the model by providing validation data as well**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7cb82964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.5741 - accuracy: 0.7974 - val_loss: 0.4097 - val_accuracy: 0.8482\n",
      "Epoch 2/10\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.3868 - accuracy: 0.8596 - val_loss: 0.3544 - val_accuracy: 0.8700\n",
      "Epoch 3/10\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.3403 - accuracy: 0.8748 - val_loss: 0.3653 - val_accuracy: 0.8677\n",
      "Epoch 4/10\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.3124 - accuracy: 0.8843 - val_loss: 0.3446 - val_accuracy: 0.8735\n",
      "Epoch 5/10\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.2940 - accuracy: 0.8912 - val_loss: 0.3417 - val_accuracy: 0.8785\n",
      "Epoch 6/10\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.2770 - accuracy: 0.8978 - val_loss: 0.3563 - val_accuracy: 0.8805\n",
      "Epoch 7/10\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.2645 - accuracy: 0.9024 - val_loss: 0.3583 - val_accuracy: 0.8768\n",
      "Epoch 8/10\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.2550 - accuracy: 0.9050 - val_loss: 0.3777 - val_accuracy: 0.8690\n",
      "Epoch 9/10\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.2446 - accuracy: 0.9085 - val_loss: 0.3177 - val_accuracy: 0.8920\n",
      "Epoch 10/10\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.2329 - accuracy: 0.9134 - val_loss: 0.3346 - val_accuracy: 0.8830\n"
     ]
    }
   ],
   "source": [
    "# Get the model architecture and compile\n",
    "#--------------------------------------------------------------------------------\n",
    "model = model_fashion_mnist()\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# split original training data (60k examples) into 2 parts: training data (50k) and validation data (10k)\n",
    "model_hist = model.fit(train_images, train_labels, validation_split=0.1, epochs = 10, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d457b9e",
   "metadata": {},
   "source": [
    "**Call Backs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bff6c907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "422/422 [==============================] - 4s 8ms/step - loss: 0.5733 - accuracy: 0.7962 - val_loss: 0.4124 - val_accuracy: 0.8450 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.3874 - accuracy: 0.8574 - val_loss: 0.3754 - val_accuracy: 0.8647 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.3407 - accuracy: 0.8759 - val_loss: 0.3711 - val_accuracy: 0.8655 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.3132 - accuracy: 0.8830 - val_loss: 0.3390 - val_accuracy: 0.8785 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.2940 - accuracy: 0.8916 - val_loss: 0.3442 - val_accuracy: 0.8703 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.2777 - accuracy: 0.8986 - val_loss: 0.3329 - val_accuracy: 0.8800 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.2656 - accuracy: 0.9024 - val_loss: 0.3103 - val_accuracy: 0.8882 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.2546 - accuracy: 0.9057 - val_loss: 0.3257 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.2432 - accuracy: 0.9095 - val_loss: 0.3439 - val_accuracy: 0.8840 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Get the model architecture and compile\n",
    "#--------------------------------------------------------------------------------\n",
    "model = model_fashion_mnist()\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Call backs are objects that are passed to the fit method to have a better control on the training process\n",
    "# we can use callbacks for...\n",
    "# 1. Early stopping the model if the validation loss is not improving\n",
    "# 2. Dynamically adjust the values of certain parameters during training\n",
    "# 3. Save the model at different checkpints during training\n",
    "\n",
    "callback_list = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=2), \n",
    "                  keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=2),\n",
    "                  keras.callbacks.ModelCheckpoint(monitor='val_loss', filepath='checkpoint_best.keras',save_best_only=True)]\n",
    "\n",
    "model_hist = model.fit(train_images, train_labels, validation_split=0.1, epochs = 10, callbacks = callback_list, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7eef14c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can load a previously checkpointed model like this and either continue training, or use it to evalute or make predictions\n",
    "model = keras.models.load_model(\"checkpoint_best.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1850c8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

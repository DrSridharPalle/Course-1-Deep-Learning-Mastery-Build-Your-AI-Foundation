{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d3b3fe",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"./images/PalleAI-Banner1.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccee792",
   "metadata": {},
   "source": [
    "# Data Augumentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9450810e",
   "metadata": {},
   "source": [
    "### Build model by training on CIFAR Dataset, but now with data augumentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84269059",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"./images/cifar3.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162adc49",
   "metadata": {},
   "source": [
    "### Import needed libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a9babbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Python packages for data wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "#Tensorflow & Keras related packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "from utils import plot_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e7e482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same steps as before. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50a78ca",
   "metadata": {},
   "source": [
    "### Load Cifar Dataset Preloaded in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24f0320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d20b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6401c5bc",
   "metadata": {},
   "source": [
    "### Understanding the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c00b88e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b3c926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee0aff2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85233eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7671e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c040726f",
   "metadata": {},
   "source": [
    "### Preprocess the Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f1c1cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39f5f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "#-------------------------------------------------------------\n",
    "train_images = train_images.astype(\"float32\") / 255 \n",
    "test_images = test_images.astype(\"float32\") / 255 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806996ce",
   "metadata": {},
   "source": [
    "### Build the Neural Network Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e96f595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1f1fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build similar neural network except we are going to add augumentation layers\n",
    "\n",
    "def model_cifar_augumented(): \n",
    "    inputs = keras.Input(shape = (32,32,3)) # Define Input shape\n",
    "    \n",
    "    augumentation_layers = keras.Sequential([layers.RandomFlip(), layers.RandomRotation(0.1),\n",
    "                                             layers.RandomZoom(0.1), layers.RandomTranslation(0.2,0.2)])\n",
    "    \n",
    "    x = augumentation_layers(inputs)\n",
    "\n",
    "    x = layers.Conv2D(filters=32, kernel_size = 3, activation=\"relu\")(x) \n",
    "    # Convolution Layer with no padding and stride=1 (default)\n",
    "    \n",
    "    x = layers.MaxPooling2D(pool_size=2, strides = (2,2))(x) \n",
    "    # MaxPool Layer with size = 2 x 2, strides = 2\n",
    "\n",
    "    x = layers.Conv2D(filters=64, kernel_size = 3, activation=\"relu\")(x) \n",
    "    # Convolution Layer with no padding and stride=1 (default)\n",
    "    \n",
    "    x = layers.MaxPooling2D(pool_size=2, strides = (2,2))(x) \n",
    "    # MaxPool Layer with size = 2 x 2, strides = 2\n",
    "\n",
    "    x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x) \n",
    "    # Convolution Layer with no padding and stride=1 (default)\n",
    "\n",
    "    x = layers.Flatten()(x) \n",
    "    # Flatten\n",
    "\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(x) \n",
    "    # Dense output Layer\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c130fc7f",
   "metadata": {},
   "source": [
    "* **Dataset size is constant**: Augmentation does not change the dataset size but increases its effective variability.\n",
    "\n",
    "* **Independently Random**: Each image in a batch undergoes independent random transformations \n",
    "\n",
    "* **Transformations Driven by Layer Parameters**: The specifics of the transformations are determined by the settings in each augmentation layer\n",
    "\n",
    "For instance, if a batch contains 32 images, each image has an independent chance of being flipped, rotated, zoomed, or translated according to the specified probabilities and ranges in the augmentation layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26a55858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                20490     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,738\n",
      "Trainable params: 113,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_cifar_augumented()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56df0fbd",
   "metadata": {},
   "source": [
    "### Compile & Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "955747da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sridh\\anaconda3\\envs\\tf2.10_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Compile the Model by configuring the loss function, optimizer type, \n",
    "#..& metrics to monitor the model performance\n",
    "\n",
    "# we will use sgd optimizer\n",
    "sgd = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9) \n",
    "\n",
    "#compile the model\n",
    "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy',  metrics = [\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14ebae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call backs\n",
    "# learning rate scheduler callback\n",
    "def lr_scheduler(epoch):\n",
    "    return 0.01 * (0.5 ** (epoch // 20))\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler) \n",
    "\n",
    "#model checkpoint callback\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(filepath = \"./models/model_cifar_augumented.keras\",\n",
    "                                                   save_best_only=True, monitor=\"val_loss\") \n",
    "\n",
    "callbacks = callbacks = [model_checkpoint, reduce_lr] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d4d291d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "1250/1250 [==============================] - 407s 313ms/step - loss: 1.9362 - accuracy: 0.2852 - val_loss: 1.9903 - val_accuracy: 0.2770 - lr: 0.0100\n",
      "Epoch 2/30\n",
      "1250/1250 [==============================] - 401s 321ms/step - loss: 1.6620 - accuracy: 0.3900 - val_loss: 1.9995 - val_accuracy: 0.2856 - lr: 0.0100\n",
      "Epoch 3/30\n",
      "1250/1250 [==============================] - 471s 377ms/step - loss: 1.5528 - accuracy: 0.4349 - val_loss: 2.0544 - val_accuracy: 0.3023 - lr: 0.0100\n",
      "Epoch 4/30\n",
      "1250/1250 [==============================] - 412s 329ms/step - loss: 1.4869 - accuracy: 0.4618 - val_loss: 2.3286 - val_accuracy: 0.2663 - lr: 0.0100\n",
      "Epoch 5/30\n",
      "1250/1250 [==============================] - 438s 350ms/step - loss: 1.4348 - accuracy: 0.4818 - val_loss: 2.2881 - val_accuracy: 0.3051 - lr: 0.0100\n",
      "Epoch 6/30\n",
      "1250/1250 [==============================] - 416s 333ms/step - loss: 1.3865 - accuracy: 0.5035 - val_loss: 2.2582 - val_accuracy: 0.2833 - lr: 0.0100\n",
      "Epoch 7/30\n",
      "1250/1250 [==============================] - 391s 313ms/step - loss: 1.3536 - accuracy: 0.5153 - val_loss: 2.2788 - val_accuracy: 0.3047 - lr: 0.0100\n",
      "Epoch 8/30\n",
      "1250/1250 [==============================] - 374s 299ms/step - loss: 1.3312 - accuracy: 0.5206 - val_loss: 2.1430 - val_accuracy: 0.3237 - lr: 0.0100\n",
      "Epoch 9/30\n",
      "1250/1250 [==============================] - 391s 313ms/step - loss: 1.3053 - accuracy: 0.5338 - val_loss: 2.2065 - val_accuracy: 0.3104 - lr: 0.0100\n",
      "Epoch 10/30\n",
      "1250/1250 [==============================] - 386s 309ms/step - loss: 1.2910 - accuracy: 0.5429 - val_loss: 2.1459 - val_accuracy: 0.3370 - lr: 0.0100\n",
      "Epoch 11/30\n",
      "1250/1250 [==============================] - 384s 307ms/step - loss: 1.2667 - accuracy: 0.5507 - val_loss: 2.2185 - val_accuracy: 0.3087 - lr: 0.0100\n",
      "Epoch 12/30\n",
      "1250/1250 [==============================] - 387s 309ms/step - loss: 1.2445 - accuracy: 0.5606 - val_loss: 2.2221 - val_accuracy: 0.3177 - lr: 0.0100\n",
      "Epoch 13/30\n",
      "1250/1250 [==============================] - 387s 309ms/step - loss: 1.2256 - accuracy: 0.5677 - val_loss: 2.3298 - val_accuracy: 0.3131 - lr: 0.0100\n",
      "Epoch 14/30\n",
      "1250/1250 [==============================] - 384s 307ms/step - loss: 1.2150 - accuracy: 0.5701 - val_loss: 2.1243 - val_accuracy: 0.3299 - lr: 0.0100\n",
      "Epoch 15/30\n",
      "1250/1250 [==============================] - 388s 311ms/step - loss: 1.2016 - accuracy: 0.5759 - val_loss: 2.1690 - val_accuracy: 0.3355 - lr: 0.0100\n",
      "Epoch 16/30\n",
      "1250/1250 [==============================] - 385s 308ms/step - loss: 1.1819 - accuracy: 0.5839 - val_loss: 2.1819 - val_accuracy: 0.3402 - lr: 0.0100\n",
      "Epoch 17/30\n",
      "1250/1250 [==============================] - 385s 308ms/step - loss: 1.1790 - accuracy: 0.5838 - val_loss: 2.4867 - val_accuracy: 0.3042 - lr: 0.0100\n",
      "Epoch 18/30\n",
      "1250/1250 [==============================] - 386s 309ms/step - loss: 1.1654 - accuracy: 0.5871 - val_loss: 2.2158 - val_accuracy: 0.3537 - lr: 0.0100\n",
      "Epoch 19/30\n",
      "1250/1250 [==============================] - 384s 307ms/step - loss: 1.1601 - accuracy: 0.5949 - val_loss: 2.1514 - val_accuracy: 0.3473 - lr: 0.0100\n",
      "Epoch 20/30\n",
      "1250/1250 [==============================] - 391s 313ms/step - loss: 1.1434 - accuracy: 0.5968 - val_loss: 2.2672 - val_accuracy: 0.3204 - lr: 0.0100\n",
      "Epoch 21/30\n",
      "1250/1250 [==============================] - 383s 307ms/step - loss: 1.0574 - accuracy: 0.6285 - val_loss: 2.2811 - val_accuracy: 0.3460 - lr: 0.0050\n",
      "Epoch 22/30\n",
      "1250/1250 [==============================] - 382s 306ms/step - loss: 1.0363 - accuracy: 0.6365 - val_loss: 2.1985 - val_accuracy: 0.3528 - lr: 0.0050\n",
      "Epoch 23/30\n",
      "1250/1250 [==============================] - 388s 311ms/step - loss: 1.0266 - accuracy: 0.6391 - val_loss: 2.2956 - val_accuracy: 0.3386 - lr: 0.0050\n",
      "Epoch 24/30\n",
      "1250/1250 [==============================] - 393s 314ms/step - loss: 1.0114 - accuracy: 0.6447 - val_loss: 2.4032 - val_accuracy: 0.3396 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "1250/1250 [==============================] - 387s 310ms/step - loss: 1.0034 - accuracy: 0.6470 - val_loss: 2.3044 - val_accuracy: 0.3504 - lr: 0.0050\n",
      "Epoch 26/30\n",
      "1250/1250 [==============================] - 405s 323ms/step - loss: 1.0039 - accuracy: 0.6470 - val_loss: 2.2419 - val_accuracy: 0.3428 - lr: 0.0050\n",
      "Epoch 27/30\n",
      "1250/1250 [==============================] - 410s 328ms/step - loss: 1.0030 - accuracy: 0.6483 - val_loss: 2.2037 - val_accuracy: 0.3474 - lr: 0.0050\n",
      "Epoch 28/30\n",
      "1250/1250 [==============================] - 494s 395ms/step - loss: 0.9887 - accuracy: 0.6528 - val_loss: 2.3179 - val_accuracy: 0.3427 - lr: 0.0050\n",
      "Epoch 29/30\n",
      "1250/1250 [==============================] - 494s 395ms/step - loss: 0.9941 - accuracy: 0.6508 - val_loss: 2.2341 - val_accuracy: 0.3551 - lr: 0.0050\n",
      "Epoch 30/30\n",
      "1250/1250 [==============================] - 424s 339ms/step - loss: 0.9827 - accuracy: 0.6577 - val_loss: 2.3194 - val_accuracy: 0.3469 - lr: 0.0050\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_images, train_labels, epochs = 30, batch_size = 32, \n",
    "                    validation_split = 0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e93733",
   "metadata": {},
   "source": [
    "### Plotting the loss & Accuracy curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9492b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284fdea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model started overfitting after 10th epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afc12d7",
   "metadata": {},
   "source": [
    "### Evaluate the trained model on previously unseen test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8073a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1f8e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to randomness of neural network initialization, numbers may be slightly different each time u train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

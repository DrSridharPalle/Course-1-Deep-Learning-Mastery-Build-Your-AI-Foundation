{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d3b3fe",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"./images/PallenceAI-Final.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccee792",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on IMDb Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2335b58c",
   "metadata": {},
   "source": [
    "### Sequence Models: Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615411e7",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"./images/sequence-transformer.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa336972",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"./images/imdb2.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162adc49",
   "metadata": {},
   "source": [
    "### Import needed libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a9babbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Python packages for data wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "#Tensorflow & Keras related packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "from utils import plot_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50a78ca",
   "metadata": {},
   "source": [
    "### Load IMDb Dataset Preloaded in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14d20b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sridh\\anaconda3\\envs\\tf2.10_env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "train, val, test = tfds.load(\n",
    "    name=\"imdb_reviews\",\n",
    "    split=[\"train[:80%]\", \"train[80%:]\", \"test\"],\n",
    "    as_supervised=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aceea5d",
   "metadata": {},
   "source": [
    "### Understanding the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76b60dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "5000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "# Lets see how many sample reviews are there in each dataset\n",
    "print (len(train))\n",
    "print (len(val))\n",
    "print (len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2025bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch the data\n",
    "train_data = train.batch(32)\n",
    "val_data = val.batch(32)\n",
    "test_data =test.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c78d5716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c6bda77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews shape (32,)\n",
      "Labels shape (32,) \n",
      "\n",
      "First Review: This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it. \n",
      "\n",
      "First Label: 0\n"
     ]
    }
   ],
   "source": [
    "#lets look at the first batch of data\n",
    "\n",
    "for reviews, labels in train_data.take(1):\n",
    "    print (\"Reviews shape\", reviews.shape)\n",
    "    print (\"Labels shape\", labels.shape, \"\\n\")\n",
    "    \n",
    "    print ('First Review:', reviews[0].numpy().decode(\"utf-8\"), \"\\n\") \n",
    "    print ('First Label:', labels[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8bb2551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First select only reviews from training data (which contains both reviews/labels) \n",
    "# ..which we will vectorize into numeric format.\n",
    "\n",
    "train_data_onlyreviews = train_data.map(lambda x,y : x) # given a tuple (x,y), output only x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc394a2a",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"./images/vectorization.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd8ca37",
   "metadata": {},
   "source": [
    "## Data prep for Sequence Models\n",
    "1. Vectorize the sequences as shown below with TextVectorization in Keras:\n",
    "* Tokenize the sequences\n",
    "* Encode the tokens into integers\n",
    "\n",
    "2. After this we can convert each integer to a corresponding vector (such as one-hot, or word embeddings). This can be \n",
    "done by a seperate one-hot layer or embedding layer directly during model building stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badfd393",
   "metadata": {},
   "source": [
    "**Vectorize by encoding to integers first**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a7c6dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras has inbuilt Text Vectorization layer that can standardize, tokenize, and \n",
    "# ..convert to indices or token vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391e45b0",
   "metadata": {},
   "source": [
    "Text Vectorization in Keras by default\n",
    "* converts to lower case\n",
    "* removes punctuation\n",
    "* split on whitepsace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f40e8c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "# this is a limit on sequence length. each sequence will be 300 words long\n",
    "max_length = 300 \n",
    "\n",
    "# this is for the vocabulary limit. max tokens to use for creating the vocabulary. \n",
    "max_tokens = 10000 \n",
    "\n",
    "text_vectorization = TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode = \"int\",\n",
    "    output_sequence_length = max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67ac32d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply vectorization on training data reviews\n",
    "\n",
    "text_vectorization.adapt(train_data_onlyreviews) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a72b6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each review is standardized, tokenized, and convered into an integer sequence\n",
    "\n",
    "train_int = train_data.map(lambda x,y: (text_vectorization(x),y)) \n",
    "val_int = val_data.map(lambda x,y: (text_vectorization(x),y)) \n",
    "test_int = test_data.map(lambda x,y: (text_vectorization(x),y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "317ac6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews shape (32, 300)\n",
      "Labels shape (32,) \n",
      "\n",
      "First Review: tf.Tensor(\n",
      "[  11   14   34  411  376   18   90   27    1    8   33 1319 4152   41\n",
      "  503    1  193   25   86  152   19   11  216  316   27   65  241  214\n",
      "    8  485   56   65   86  115   95   22 5749   11   93  635  738   11\n",
      "   18    7   34  398 9897  169 2480  410    2   88 1203  137   67  144\n",
      "   52    2    1 7096   67  245   65 2937   16    1 2793    1    1 1444\n",
      " 5053    3   40    1 1663   17 4152   14  157   19    4 1203  853 7809\n",
      "    8    4   18   12   14 3837    5   98  146 1221   10  231  688   12\n",
      "   48   25   93   39   11 7514  152   39 1319    1   50  409   10   95\n",
      " 1156  845  140    9    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0], shape=(300,), dtype=int64) \n",
      "\n",
      "First Label: 0\n"
     ]
    }
   ],
   "source": [
    "# lets look again at the first batch of data, now that reviews are converted into integers\n",
    "\n",
    "for reviews, labels in train_int.take(1):\n",
    "    print (\"Reviews shape\", reviews.shape)\n",
    "    print (\"Labels shape\", labels.shape, \"\\n\")\n",
    "    print ('First Review:', reviews[0], \"\\n\")\n",
    "    print ('First Label:', labels[0].numpy())\n",
    "\n",
    "# Each review is converted into a 300 length integer sequence. Each batch has 32 reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806996ce",
   "metadata": {},
   "source": [
    "## 1. Build the Transformer Encoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd437772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the seeds for model initialization/training for reproducibility\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a149b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "max_tokens = 10000  # Size of the vocabulary\n",
    "max_length = 300  # Maximum length of a sequence\n",
    "\n",
    "embed_dim = 128  # Embedding dimension\n",
    "num_heads = 4  # Number of attention heads\n",
    "ff_dim = 128  # Dimension of the feed-forward network within the transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f35e495",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"./images/transformer_encoder2.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca9eca8",
   "metadata": {},
   "source": [
    "**Transformer Encoder Block**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b10ade07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Transformer Encoder block using built-in layers\n",
    "\n",
    "def transformer_encoder(inputs, embed_dim, num_heads, ff_dim):\n",
    "    \n",
    "    # Multi-Head Attention\n",
    "    attn_output = layers.MultiHeadAttention(key_dim=embed_dim, num_heads=num_heads)(inputs, inputs, inputs)\n",
    "    \n",
    "    # Residual Connection: # adding attn_output & inputs\n",
    "    residual_connection1 = inputs + attn_output\n",
    "    \n",
    "    # Layer Normalization\n",
    "    out1 = layers.LayerNormalization(epsilon=1e-6)(residual_connection1) \n",
    "    \n",
    "    # Feed-Forward Network\n",
    "    ffn_output = layers.Dense(ff_dim, activation=\"relu\")(out1)\n",
    "    ffn_output = layers.Dense(embed_dim)(ffn_output)\n",
    "   \n",
    "    # Residual Connection: Adding ffn_output & out1\n",
    "    residual_connection2 = out1 + ffn_output\n",
    "    \n",
    "    # Layer Normalization\n",
    "    out2 = layers.LayerNormalization(epsilon=1e-6)(residual_connection2) \n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d2b450",
   "metadata": {},
   "source": [
    "**Word Order with Fixed Positional Embeddings using sine/cosine functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b425ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Positional Encodings\n",
    "\n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(max_length, d_model):\n",
    "    angle_rads = get_angles(np.arange(max_length)[:, np.newaxis], \n",
    "                            np.arange(d_model)[np.newaxis, :], d_model)\n",
    "    \n",
    "    # Apply the sin function to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    \n",
    "    # Apply the cos function to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    # from (position, d_model)) to (batch_size, position, d_model) for broadcasting\n",
    "    pos_encoding = angle_rads[np.newaxis, ...] \n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de6569c",
   "metadata": {},
   "source": [
    "**Build the complete Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18069ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "def model_transformer_encoder(): \n",
    "    \n",
    "    # Define Input shape\n",
    "    inputs = keras.Input(shape = (max_length,), dtype=\"int64\") \n",
    "    \n",
    "    # Define word embedding layer.\n",
    "    # Word embeddings of each token are calculated as part of training.\n",
    "    embeddings = layers.Embedding(input_dim = max_tokens, output_dim=embed_dim, mask_zero=True)(inputs) \n",
    "      \n",
    "    \n",
    "    # Positional embeddings are fixed here. \n",
    "    pos_encoding = positional_encoding(max_length, embed_dim)\n",
    "    \n",
    "    # Add word embeddings & fixed positional embeddings\n",
    "    embeddings = embeddings + pos_encoding\n",
    "    \n",
    "    # Adding Transformer Encoder layers\n",
    "    x = transformer_encoder(embeddings, embed_dim, num_heads, ff_dim)\n",
    "    # this layer ultimately results in Context aware embeddings after training\n",
    "    \n",
    "    # GlobalMaxPooling1D selects most important feature from each wordembedding across entire sentence \n",
    "    # Effectively summarizing the essence of sentence into a single vector \n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    #  Dropout layer\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    # Final output layer\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26a55858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 300, 128)     1280000     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 300, 128)    0           ['embedding[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 300, 128)    263808      ['tf.__operators__.add[0][0]',   \n",
      " dAttention)                                                      'tf.__operators__.add[0][0]',   \n",
      "                                                                  'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 300, 128)    0           ['tf.__operators__.add[0][0]',   \n",
      " mbda)                                                            'multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 300, 128)    256         ['tf.__operators__.add_1[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 300, 128)     16512       ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 300, 128)     16512       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 300, 128)    0           ['layer_normalization[0][0]',    \n",
      " mbda)                                                            'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 300, 128)    256         ['tf.__operators__.add_2[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 128)         0           ['layer_normalization_1[0][0]']  \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['global_max_pooling1d[0][0]']   \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            129         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,577,473\n",
      "Trainable params: 1,577,473\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_transformer_encoder()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65f8f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_transformer_encoder()\n",
    "path = Path(\"./models/model_transformer_encoder_fixedpositions.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73846f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will reuse this function to train and evaluate for convenience\n",
    "def train_evaluate(model,path,train,val,test):\n",
    "    \n",
    "    # call backs\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = path,\n",
    "                                                       save_best_only=True) # Save only best model\n",
    "    \n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, \n",
    "                                                 restore_best_weights=True)\n",
    "    callbacks = [checkpoint_cb,earlystop_cb]\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=\"rmsprop\", loss='binary_crossentropy',  metrics = [\"accuracy\"])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(train, validation_data = val, callbacks=callbacks, epochs=20)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(test)\n",
    "    \n",
    "    return (history,test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97ab299f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 28s 35ms/step - loss: 0.7345 - accuracy: 0.4985 - val_loss: 0.6957 - val_accuracy: 0.4938\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 18s 29ms/step - loss: 0.6469 - accuracy: 0.5964 - val_loss: 0.5553 - val_accuracy: 0.7292\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 17s 28ms/step - loss: 0.4849 - accuracy: 0.7741 - val_loss: 0.4092 - val_accuracy: 0.8204\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 19s 30ms/step - loss: 0.3522 - accuracy: 0.8490 - val_loss: 0.3452 - val_accuracy: 0.8474\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 0.2728 - accuracy: 0.8899 - val_loss: 0.3437 - val_accuracy: 0.8530\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 18s 29ms/step - loss: 0.2196 - accuracy: 0.9148 - val_loss: 0.3724 - val_accuracy: 0.8464\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 0.1846 - accuracy: 0.9302 - val_loss: 0.3654 - val_accuracy: 0.8498\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 20s 31ms/step - loss: 0.1526 - accuracy: 0.9441 - val_loss: 0.3867 - val_accuracy: 0.8526\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 20s 32ms/step - loss: 0.1292 - accuracy: 0.9544 - val_loss: 0.4087 - val_accuracy: 0.8454\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 20s 33ms/step - loss: 0.1072 - accuracy: 0.9631 - val_loss: 0.4464 - val_accuracy: 0.8448\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 0.3543 - accuracy: 0.8470\n"
     ]
    }
   ],
   "source": [
    "(history_te,test_accuracy_te) = train_evaluate(model,path,\n",
    "                                               train_int,\n",
    "                                               val_int,\n",
    "                                               test_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b60ad22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test data set is 0.847000002861023\n"
     ]
    }
   ],
   "source": [
    "print (f\"Accuracy on the test data set is {test_accuracy_te}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6737b1f2",
   "metadata": {},
   "source": [
    "## 2. Transformer Encoder with Learnable Positional Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b9a3cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this we will define custom classes subclassing the keras layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b956771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the seeds for model initialization/training for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4ab706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "max_tokens = 10000  # Size of the vocabulary\n",
    "max_length = 300  # Maximum length of a sequence\n",
    "\n",
    "embed_dim = 128  # Embedding dimension\n",
    "num_heads = 4  # Number of attention heads\n",
    "ff_dim = 128  # Dimension of the feed-forward network within the transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a504fd13",
   "metadata": {},
   "source": [
    "### Build Positional Embedding Layer custom class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10c880a",
   "metadata": {},
   "source": [
    "**What Do Learnable Positional Embeddings Learn?**\n",
    "\n",
    "* In essence, learnable positional embeddings give the model the freedom to learn how position interacts with the token embeddings and the task at hand. \n",
    "* While we know the positions explicitly (1, 2, 3, etc.), the model might learn that certain positions (e.g., the middle or end of a sequence) should be weighted more heavily for certain tasks.\n",
    "\n",
    "For example:\n",
    "\n",
    "* For sentiment analysis, words near the end of a sentence might carry more weight because they often summarize the overall sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ebb93af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, max_tokens, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # Word embedding layer\n",
    "        self.token_embeddings = layers.Embedding(input_dim=max_tokens, output_dim=embed_dim, \n",
    "                                                 mask_zero=True)\n",
    "        # Position embeddings\n",
    "        self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=embed_dim) \n",
    "        \n",
    "        # both the above embeddings are initialized randomly first and \n",
    "        # ....will be calculated as part of training process.\n",
    "        \n",
    "        self.sequence_length = sequence_length\n",
    "        self.max_tokens = max_tokens\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        \n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        \n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return self.token_embeddings.compute_mask(inputs, mask)\n",
    "    \n",
    "        #The compute_mask method in a custom layer ensures that the \n",
    "        #...masking information is correctly propagated through the layers.\n",
    "        # without this the mask may not be propagated properly through the sebsequent layers.\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"max_tokens\": self.max_tokens,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0729351",
   "metadata": {},
   "source": [
    "### Build Transformer Encoder Layer Custom Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7612a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        \n",
    "        #Attention Layers\n",
    "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        \n",
    "        self.ffn = keras.Sequential([\n",
    "            layers.Dense(ff_dim, activation=\"relu\"),\n",
    "            layers.Dense(embed_dim),])\n",
    "        \n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            # reshape since the attention layer expects 3d or 4d: \n",
    "            # ..(batch_size, num_heads, seq_length, seq_length)\n",
    "            mask = mask[:, tf.newaxis, :] \n",
    "        \n",
    "        # Attention\n",
    "        attn_output = self.attention(inputs, inputs, attention_mask=mask)  \n",
    "        \n",
    "        # Residual connection\n",
    "        residual_connection1 = inputs + attn_output    \n",
    "        \n",
    "        # Layer Normalization\n",
    "        out1 = self.layernorm1(residual_connection1)\n",
    "        \n",
    "        # Feed forward dense layer\n",
    "        ffn_output = self.ffn(out1)\n",
    "        \n",
    "        # Residual connection\n",
    "        residual_connection2 = out1 + ffn_output\n",
    "        \n",
    "        # Layer Normalization\n",
    "        out2 = self.layernorm2(residual_connection2)\n",
    "        \n",
    "        return out2\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"ff_dim\": self.ff_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56df0fbd",
   "metadata": {},
   "source": [
    "**Build the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e0cf58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_transformer_encoder2():\n",
    "    \n",
    "    # Define input shape\n",
    "    inputs = keras.Input(shape=(max_length,), dtype=\"int64\") \n",
    "\n",
    "    # Positional Embedding Layer using the above defined position embedding class custom layer\n",
    "    x = PositionalEmbedding(sequence_length=max_length, max_tokens=max_tokens, embed_dim=embed_dim)(inputs)\n",
    "      \n",
    "    # Transformer Encoder Layer\n",
    "    x = TransformerEncoder(embed_dim=embed_dim, ff_dim=ff_dim, num_heads=num_heads)(x)\n",
    "    \n",
    "    # GlobalMaxPooling1D layer\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    # Dropout before the final classification layer\n",
    "    x = layers.Dropout(0.5)(x) \n",
    "    \n",
    "    # Final Dense layer\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b857896b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 300)]             0         \n",
      "                                                                 \n",
      " positional_embedding (Posit  (None, 300, 128)         1318400   \n",
      " ionalEmbedding)                                                 \n",
      "                                                                 \n",
      " transformer_encoder (Transf  (None, 300, 128)         297344    \n",
      " ormerEncoder)                                                   \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,615,873\n",
      "Trainable params: 1,615,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = model_transformer_encoder2()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34ae5010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only difference between the previous model & the above one in terms of total parameters\n",
    "# We have an additional 300 * 128 = 38400 paramters for positional embeddings \n",
    "#...which will now be learned instead of being fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4020658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1577473+(300*128) = 1,615,873"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "837eca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_transformer_encoder2()\n",
    "path = Path(\"./models/model_transformer_encoder_learnedpositions.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3410c4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 25s 34ms/step - loss: 0.4896 - accuracy: 0.7605 - val_loss: 0.2970 - val_accuracy: 0.8758\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 20s 32ms/step - loss: 0.2701 - accuracy: 0.8920 - val_loss: 0.2929 - val_accuracy: 0.8788\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 20s 31ms/step - loss: 0.2112 - accuracy: 0.9194 - val_loss: 0.2898 - val_accuracy: 0.8816\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 0.1768 - accuracy: 0.9331 - val_loss: 0.3184 - val_accuracy: 0.8742\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 19s 30ms/step - loss: 0.1562 - accuracy: 0.9415 - val_loss: 0.3041 - val_accuracy: 0.8804\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 0.1390 - accuracy: 0.9482 - val_loss: 0.3873 - val_accuracy: 0.8722\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 0.1250 - accuracy: 0.9545 - val_loss: 0.3549 - val_accuracy: 0.8604\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 20s 32ms/step - loss: 0.1164 - accuracy: 0.9559 - val_loss: 0.3395 - val_accuracy: 0.8786\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.3229 - accuracy: 0.8673\n"
     ]
    }
   ],
   "source": [
    "(history_te2,test_accuracy_te2) = train_evaluate(model,path,\n",
    "                                                 train_int,\n",
    "                                                 val_int,\n",
    "                                                 test_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b9ec99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test data set is 0.8672800064086914\n"
     ]
    }
   ],
   "source": [
    "print (f\"Accuracy on the test data set is {test_accuracy_te2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84482611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d3b3fe",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"./images/PallenceAI-Final.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccee792",
   "metadata": {},
   "source": [
    "# Machine Translation: Sequence to Sequence Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa336972",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"./images/mt2.webp\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162adc49",
   "metadata": {},
   "source": [
    "### Import needed libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a9babbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Python packages for data wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "#Tensorflow & Keras related packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "from utils import plot_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ebcf38",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e81043b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First download the dataset \n",
    "# ..from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d885708",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"data/spa-eng/spa.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e702b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "sentence_pairs = []\n",
    "for line in lines:\n",
    "    english, spanish = line.split(\"\\t\")\n",
    "    sentence_pairs.append((english, spanish))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8805920b",
   "metadata": {},
   "source": [
    "### Understand & Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95199abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Go.', 'Ve.'),\n",
       " ('Go.', 'Vete.'),\n",
       " ('Go.', 'Vaya.'),\n",
       " ('Go.', 'Váyase.'),\n",
       " ('Hi.', 'Hola.'),\n",
       " ('Run!', '¡Corre!'),\n",
       " ('Run.', 'Corred.'),\n",
       " ('Who?', '¿Quién?'),\n",
       " ('Fire!', '¡Fuego!'),\n",
       " ('Fire!', '¡Incendio!')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_pairs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38381f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(sentence_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329d4742",
   "metadata": {},
   "source": [
    "**Convert the dataset into a tf.data.Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b88684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset into a tf.data.Dataset\n",
    "english = [pairs[0] for pairs in sentence_pairs]\n",
    "spanish = [pairs[1] for pairs in sentence_pairs]\n",
    "all_data = tf.data.Dataset.from_tensor_slices((english,spanish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4b09e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6fd08b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))\n"
     ]
    }
   ],
   "source": [
    "print(all_data.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e70d605d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118964"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data) # Total 118964 sentence pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92151695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 118964\n"
     ]
    }
   ],
   "source": [
    "length = all_data.cardinality().numpy()\n",
    "print(f\"Length of dataset: {length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd9a2871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'He wants to live as long as he can.'>, <tf.Tensor: shape=(), dtype=string, numpy=b'Quiere vivir tanto tiempo como pueda.'>)\n"
     ]
    }
   ],
   "source": [
    "for element in all_data.take(1):\n",
    "    print (element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3c9c9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: He wants to live as long as he can.\n",
      "Spanish: Quiere vivir tanto tiempo como pueda.\n",
      "English: He has a large truck.\n",
      "Spanish: Él tiene un gran camión.\n"
     ]
    }
   ],
   "source": [
    "# Displaying a sample. First two sentence pairs\n",
    "for en,sp in all_data.take(2):\n",
    "    print(\"English:\", en.numpy().decode('utf-8'))\n",
    "    print(\"Spanish:\", sp.numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e45fe6",
   "metadata": {},
   "source": [
    "**Add [start], [end] to target sentences (spanish)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bb988e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: He wants to live as long as he can.\n",
      "Spanish: [START] Quiere vivir tanto tiempo como pueda. [END]\n",
      "English: He has a large truck.\n",
      "Spanish: [START] Él tiene un gran camión. [END]\n",
      "English: When did you see my scar?\n",
      "Spanish: [START] ¿Cuándo viste mi cicatriz? [END]\n"
     ]
    }
   ],
   "source": [
    "# We need to add [start], [end] tokens to target sentences \n",
    "#..so that the model will start predicting when [start] is given as first token, \n",
    "#..and when it predicts [end] or reaches max sequence length it will stop\n",
    "\n",
    "def add_tokens(source_sentence, target_sentence):\n",
    "    target_sentence = tf.strings.join([\"[START] \", target_sentence, \" [END]\"])\n",
    "    return source_sentence, target_sentence\n",
    "\n",
    "# Apply the extra tokens to the dataset. mainly to the spanish sentences.\n",
    "all_data = all_data.map(add_tokens)\n",
    "\n",
    "# Displaying a sample\n",
    "for en,sp in all_data.take(3):\n",
    "    print(\"English:\", en.numpy().decode('utf-8'))\n",
    "    print(\"Spanish:\", sp.numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2f128a",
   "metadata": {},
   "source": [
    "**Split the data into train, val, test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cc5417c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 83276\n",
      "Validation size: 17844\n",
      "Test size: 17844\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of samples\n",
    "total_samples = all_data.cardinality().numpy()\n",
    "\n",
    "# Calculate the sizes of new splits\n",
    "test_size = val_size = int(0.15 * total_samples)\n",
    "train_size = total_samples - test_size - val_size\n",
    "\n",
    "# Split the dataset\n",
    "train_data = all_data.take(train_size)\n",
    "val_data = all_data.skip(train_size).take(val_size)\n",
    "test_data = all_data.skip(train_size + val_size).take(test_size)\n",
    "\n",
    "# Print the sizes of the new splits\n",
    "print(\"Train size:\", train_size)\n",
    "print(\"Validation size:\", val_size)\n",
    "print(\"Test size:\", test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b94ebb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: He wants to live as long as he can.\n",
      "Spanish: [START] Quiere vivir tanto tiempo como pueda. [END]\n",
      "English: He has a large truck.\n",
      "Spanish: [START] Él tiene un gran camión. [END]\n",
      "English: When did you see my scar?\n",
      "Spanish: [START] ¿Cuándo viste mi cicatriz? [END]\n"
     ]
    }
   ],
   "source": [
    "for en,sp in train_data.take(3):\n",
    "    print(\"English:\", en.numpy().decode('utf-8'))\n",
    "    print(\"Spanish:\", sp.numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a16a24",
   "metadata": {},
   "source": [
    "**Vectorize the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "586a521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going forward input source will be english language, target will be spanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc17c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "\n",
    "VOCAB_SIZE = 15000 # Max tokens\n",
    "MAX_SEQ_LEN = 20 # Max sequence length\n",
    "\n",
    "EMBED_DIM = 256 # Word embedding vector dimension\n",
    "HIDDEN_DIM = 1024 # Hidden units dimension\n",
    "\n",
    "BATCH_SIZE = 64 # Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab9320bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vectorizers\n",
    "\n",
    "\n",
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "# Source data vectorizer - English\n",
    "source_vectorizer = layers.TextVectorization(\n",
    "    max_tokens = VOCAB_SIZE,\n",
    "    output_mode = \"int\",\n",
    "    output_sequence_length = MAX_SEQ_LEN,\n",
    ")\n",
    "\n",
    "\n",
    "# we will have some custom standardization\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    \n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
    "\n",
    "# Target data vectorizer -  Spanish\n",
    "target_vectorizer = layers.TextVectorization(\n",
    "    max_tokens = VOCAB_SIZE,\n",
    "    output_mode = \"int\",\n",
    "    \n",
    "    # We add extra token since target will be offset by one token\n",
    "    output_sequence_length = MAX_SEQ_LEN + 1, \n",
    "    standardize=custom_standardization,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "744406a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt the vectorizers to the dataset. Meaning creating the vocabulary for respective languages.\n",
    "source_vectorizer.adapt(train_data.map(lambda x,y: x)) # for english sentences\n",
    "target_vectorizer.adapt(train_data.map(lambda x,y: y)) # for spanish sentences\n",
    "\n",
    "# This can take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6041ae55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'the',\n",
       " 'i',\n",
       " 'to',\n",
       " 'you',\n",
       " 'tom',\n",
       " 'a',\n",
       " 'is',\n",
       " 'he',\n",
       " 'in',\n",
       " 'of',\n",
       " 'that',\n",
       " 'it',\n",
       " 'was',\n",
       " 'do',\n",
       " 'this',\n",
       " 'have',\n",
       " 'me',\n",
       " 'my',\n",
       " 'for',\n",
       " 'she',\n",
       " 'dont',\n",
       " 'what',\n",
       " 'are',\n",
       " 'his',\n",
       " 'mary',\n",
       " 'we',\n",
       " 'your',\n",
       " 'on',\n",
       " 'be',\n",
       " 'want',\n",
       " 'with',\n",
       " 'not',\n",
       " 'im',\n",
       " 'and',\n",
       " 'like',\n",
       " 'at',\n",
       " 'know',\n",
       " 'him',\n",
       " 'can',\n",
       " 'go',\n",
       " 'her',\n",
       " 'has',\n",
       " 'will',\n",
       " 'there',\n",
       " 'its',\n",
       " 'time',\n",
       " 'they',\n",
       " 'as',\n",
       " 'very',\n",
       " 'how',\n",
       " 'did',\n",
       " 'were',\n",
       " 'had',\n",
       " 'all',\n",
       " 'here',\n",
       " 'about',\n",
       " 'up',\n",
       " 'didnt',\n",
       " 'think',\n",
       " 'get',\n",
       " 'out',\n",
       " 'when',\n",
       " 'from',\n",
       " 'cant',\n",
       " 'if',\n",
       " 'an',\n",
       " 'no',\n",
       " 'one',\n",
       " 'going',\n",
       " 'doesnt',\n",
       " 'would',\n",
       " 'by',\n",
       " 'see',\n",
       " 'why',\n",
       " 'come',\n",
       " 'good',\n",
       " 'ill',\n",
       " 'please',\n",
       " 'just',\n",
       " 'youre',\n",
       " 'who',\n",
       " 'so',\n",
       " 'need',\n",
       " 'been',\n",
       " 'help',\n",
       " 'more',\n",
       " 'tell',\n",
       " 'now',\n",
       " 'but',\n",
       " 'where',\n",
       " 'than',\n",
       " 'never',\n",
       " 'am',\n",
       " 'too',\n",
       " 'got',\n",
       " 'some',\n",
       " 'much',\n",
       " 'last',\n",
       " 'us',\n",
       " 'something',\n",
       " 'car',\n",
       " 'take',\n",
       " 'money',\n",
       " 'day',\n",
       " 'should',\n",
       " 'could',\n",
       " 'ive',\n",
       " 'home',\n",
       " 'work',\n",
       " 'well',\n",
       " 'people',\n",
       " 'back',\n",
       " 'went',\n",
       " 'told',\n",
       " 'many',\n",
       " 'our',\n",
       " 'house',\n",
       " 'book',\n",
       " 'really',\n",
       " 'hes',\n",
       " 'does',\n",
       " 'any',\n",
       " 'said',\n",
       " 'lot',\n",
       " 'anything',\n",
       " 'two',\n",
       " 'only',\n",
       " 'say',\n",
       " 'always',\n",
       " 'make',\n",
       " 'school',\n",
       " 'eat',\n",
       " 'isnt',\n",
       " 'give',\n",
       " 'new',\n",
       " 'today',\n",
       " 'made',\n",
       " 'room',\n",
       " 'thought',\n",
       " 'thats',\n",
       " 'french',\n",
       " 'right',\n",
       " 'must',\n",
       " 'speak',\n",
       " 'toms',\n",
       " 'long',\n",
       " 'old',\n",
       " 'love',\n",
       " 'father',\n",
       " 'look',\n",
       " 'man',\n",
       " 'lets',\n",
       " 'every',\n",
       " 'let',\n",
       " 'three',\n",
       " 'night',\n",
       " 'still',\n",
       " 'tomorrow',\n",
       " 'before',\n",
       " 'asked',\n",
       " 'wanted',\n",
       " 'talk',\n",
       " 'boston',\n",
       " 'off',\n",
       " 'id',\n",
       " 'left',\n",
       " 'little',\n",
       " 'put',\n",
       " 'dog',\n",
       " 'way',\n",
       " 'whats',\n",
       " 'or',\n",
       " 'again',\n",
       " 'nothing',\n",
       " 'into',\n",
       " 'may',\n",
       " 'leave',\n",
       " 'after',\n",
       " 'yesterday',\n",
       " 'years',\n",
       " 'saw',\n",
       " 'job',\n",
       " 'over',\n",
       " 'live',\n",
       " 'english',\n",
       " 'better',\n",
       " 'stay',\n",
       " 'came',\n",
       " 'wont',\n",
       " 'first',\n",
       " 'down',\n",
       " 'everything',\n",
       " 'buy',\n",
       " 'play',\n",
       " 'mother',\n",
       " 'read',\n",
       " 'them',\n",
       " 'other',\n",
       " 'happy',\n",
       " 'next',\n",
       " 'life',\n",
       " 'theres',\n",
       " 'find',\n",
       " 'wants',\n",
       " 'children',\n",
       " 'stop',\n",
       " 'took',\n",
       " 'couldnt',\n",
       " 'ask',\n",
       " 'these',\n",
       " 'call',\n",
       " 'understand',\n",
       " 'bought',\n",
       " 'morning',\n",
       " 'friends',\n",
       " 'believe',\n",
       " 'away',\n",
       " 'their',\n",
       " 'doing',\n",
       " 'keep',\n",
       " 'problem',\n",
       " 'feel',\n",
       " 'used',\n",
       " 'door',\n",
       " 'ever',\n",
       " 'lost',\n",
       " 'late',\n",
       " 'hard',\n",
       " 'gave',\n",
       " 'happened',\n",
       " 'already',\n",
       " 'sure',\n",
       " 'year',\n",
       " 'soon',\n",
       " 'without',\n",
       " 'enough',\n",
       " 'wrong',\n",
       " 'remember',\n",
       " 'best',\n",
       " 'water',\n",
       " 'married',\n",
       " 'friend',\n",
       " 'even',\n",
       " 'things',\n",
       " 'because',\n",
       " 'bad',\n",
       " 'marys',\n",
       " 'busy',\n",
       " 'wasnt',\n",
       " 'knows',\n",
       " 'hear',\n",
       " 'alone',\n",
       " 'thing',\n",
       " 'beautiful',\n",
       " 'wait',\n",
       " 'often',\n",
       " 'likes',\n",
       " 'bed',\n",
       " 'looking',\n",
       " 'week',\n",
       " 'name',\n",
       " 'party',\n",
       " 'heard',\n",
       " 'found',\n",
       " 'try',\n",
       " 'teacher',\n",
       " 'done',\n",
       " 'able',\n",
       " 'same',\n",
       " 'seen',\n",
       " 'theyre',\n",
       " 'train',\n",
       " 'idea',\n",
       " 'looks',\n",
       " 'food',\n",
       " 'cold',\n",
       " 'big',\n",
       " 'boy',\n",
       " 'tired',\n",
       " 'answer',\n",
       " 'john',\n",
       " 'true',\n",
       " 'coffee',\n",
       " 'around',\n",
       " 'brother',\n",
       " 'being',\n",
       " 'knew',\n",
       " 'drink',\n",
       " 'watch',\n",
       " 'person',\n",
       " 'use',\n",
       " 'learn',\n",
       " 'everyone',\n",
       " 'shes',\n",
       " 'wish',\n",
       " 'open',\n",
       " 'died',\n",
       " 'while',\n",
       " 'bus',\n",
       " 'which',\n",
       " 'letter',\n",
       " 'hope',\n",
       " 'books',\n",
       " 'another',\n",
       " 'met',\n",
       " 'almost',\n",
       " 'study',\n",
       " 'someone',\n",
       " 'days',\n",
       " 'young',\n",
       " 'anyone',\n",
       " 'yet',\n",
       " 'world',\n",
       " 'mind',\n",
       " 'monday',\n",
       " 'youll',\n",
       " 'doctor',\n",
       " 'those',\n",
       " 'japan',\n",
       " 'each',\n",
       " 'talking',\n",
       " 'girl',\n",
       " 'parents',\n",
       " 'truth',\n",
       " 'sleep',\n",
       " 'pay',\n",
       " 'place',\n",
       " 'walk',\n",
       " 'seems',\n",
       " 'lunch',\n",
       " 'kind',\n",
       " 'happen',\n",
       " 'few',\n",
       " 'sister',\n",
       " 'both',\n",
       " 'turn',\n",
       " 'most',\n",
       " 'family',\n",
       " 'once',\n",
       " 'care',\n",
       " 'write',\n",
       " 'early',\n",
       " 'havent',\n",
       " 'difficult',\n",
       " 'looked',\n",
       " 'getting',\n",
       " 'ten',\n",
       " 'own',\n",
       " 'great',\n",
       " 'dinner',\n",
       " 'tried',\n",
       " 'angry',\n",
       " 'together',\n",
       " 'until',\n",
       " 'plan',\n",
       " 'wouldnt',\n",
       " 'coming',\n",
       " 'tv',\n",
       " 'else',\n",
       " 'rain',\n",
       " 'arent',\n",
       " 'afraid',\n",
       " 'nobody',\n",
       " 'himself',\n",
       " 'youve',\n",
       " 'yourself',\n",
       " 'favorite',\n",
       " 'country',\n",
       " 'waiting',\n",
       " 'since',\n",
       " 'cat',\n",
       " 'mine',\n",
       " 'table',\n",
       " 'child',\n",
       " 'show',\n",
       " 'ago',\n",
       " 'hand',\n",
       " 'says',\n",
       " 'matter',\n",
       " 'lives',\n",
       " 'five',\n",
       " 'eating',\n",
       " 'trying',\n",
       " 'police',\n",
       " 'wife',\n",
       " 'reading',\n",
       " 'phone',\n",
       " 'such',\n",
       " 'question',\n",
       " 'hurt',\n",
       " 'ready',\n",
       " 'hours',\n",
       " 'playing',\n",
       " 'meet',\n",
       " 'ate',\n",
       " 'everybody',\n",
       " 'drive',\n",
       " 'accident',\n",
       " 'swim',\n",
       " 'meeting',\n",
       " 'myself',\n",
       " 'hate',\n",
       " 'sick',\n",
       " 'might',\n",
       " 'usually',\n",
       " 'tonight',\n",
       " 'finished',\n",
       " 'sorry',\n",
       " 'nice',\n",
       " 'small',\n",
       " 'office',\n",
       " 'month',\n",
       " 'start',\n",
       " 'minutes',\n",
       " 'decided',\n",
       " 'window',\n",
       " 'story',\n",
       " 'important',\n",
       " 'far',\n",
       " 'trouble',\n",
       " 'started',\n",
       " 'japanese',\n",
       " 'ran',\n",
       " 'having',\n",
       " 'easy',\n",
       " 'word',\n",
       " 'times',\n",
       " 'shouldnt',\n",
       " 'park',\n",
       " 'city',\n",
       " 'arrived',\n",
       " 'station',\n",
       " 'called',\n",
       " 'woman',\n",
       " 'goes',\n",
       " 'felt',\n",
       " 'shoes',\n",
       " 'needs',\n",
       " 'music',\n",
       " 'broke',\n",
       " 'under',\n",
       " 'working',\n",
       " 'son',\n",
       " 'stupid',\n",
       " 'homework',\n",
       " 'fire',\n",
       " 'anymore',\n",
       " 'students',\n",
       " 'town',\n",
       " 'mistake',\n",
       " 'movie',\n",
       " 'gone',\n",
       " 'fast',\n",
       " 'tennis',\n",
       " 'pretty',\n",
       " 'game',\n",
       " 'quite',\n",
       " 'hot',\n",
       " 'song',\n",
       " 'red',\n",
       " 'thank',\n",
       " 'fun',\n",
       " 'eyes',\n",
       " 'run',\n",
       " 'christmas',\n",
       " 'change',\n",
       " 'rich',\n",
       " 'cake',\n",
       " 'studying',\n",
       " 'six',\n",
       " 'lived',\n",
       " 'against',\n",
       " 'visit',\n",
       " 'then',\n",
       " 'number',\n",
       " 'comes',\n",
       " 'bring',\n",
       " 'afternoon',\n",
       " 'picture',\n",
       " 'australia',\n",
       " 'river',\n",
       " 'language',\n",
       " 'forget',\n",
       " 'spend',\n",
       " 'present',\n",
       " 'breakfast',\n",
       " 'turned',\n",
       " 'large',\n",
       " 'weather',\n",
       " 'smoking',\n",
       " 'listen',\n",
       " 'end',\n",
       " 'close',\n",
       " 'summer',\n",
       " 'makes',\n",
       " 'caught',\n",
       " 'advice',\n",
       " 'longer',\n",
       " 'fell',\n",
       " 'along',\n",
       " 'watching',\n",
       " 'sit',\n",
       " 'milk',\n",
       " 'finish',\n",
       " 'began',\n",
       " 'weve',\n",
       " 'kept',\n",
       " 'fish',\n",
       " 'war',\n",
       " 'hands',\n",
       " 'men',\n",
       " 'mean',\n",
       " 'face',\n",
       " 'dream',\n",
       " 'class',\n",
       " 'surprised',\n",
       " 'loves',\n",
       " 'kill',\n",
       " 'interesting',\n",
       " 'tree',\n",
       " 'taking',\n",
       " 'snow',\n",
       " 'born',\n",
       " 'wonder',\n",
       " 'through',\n",
       " 'box',\n",
       " 'baby',\n",
       " 'youd',\n",
       " 'making',\n",
       " 'hair',\n",
       " 'die',\n",
       " 'camera',\n",
       " 'works',\n",
       " 'older',\n",
       " 'near',\n",
       " 'hotel',\n",
       " 'sometimes',\n",
       " 'rather',\n",
       " 'full',\n",
       " 'trust',\n",
       " 'street',\n",
       " 'secret',\n",
       " 'miss',\n",
       " 'light',\n",
       " 'hurry',\n",
       " 'free',\n",
       " 'death',\n",
       " 'became',\n",
       " 'whos',\n",
       " 'living',\n",
       " 'hour',\n",
       " 'cut',\n",
       " 'short',\n",
       " 'dark',\n",
       " 'student',\n",
       " 'spent',\n",
       " 'seem',\n",
       " 'news',\n",
       " 'later',\n",
       " 'hospital',\n",
       " 'cannot',\n",
       " 'birthday',\n",
       " 'stopped',\n",
       " 'hungry',\n",
       " 'dollars',\n",
       " 'thinks',\n",
       " 'thinking',\n",
       " 'company',\n",
       " 'clean',\n",
       " 'bicycle',\n",
       " 'america',\n",
       " 'wine',\n",
       " 'sat',\n",
       " 'rest',\n",
       " 'questions',\n",
       " 'gets',\n",
       " 'age',\n",
       " 'white',\n",
       " 'oclock',\n",
       " 'killed',\n",
       " 'hit',\n",
       " 'hasnt',\n",
       " 'computer',\n",
       " 'chance',\n",
       " 'careful',\n",
       " 'canadian',\n",
       " 'bit',\n",
       " 'tokyo',\n",
       " 'forgot',\n",
       " 'eaten',\n",
       " 'clothes',\n",
       " 'tea',\n",
       " 'glad',\n",
       " 'flowers',\n",
       " 'daughter',\n",
       " 'possible',\n",
       " 'moment',\n",
       " 'high',\n",
       " 'dead',\n",
       " 'worked',\n",
       " 'sing',\n",
       " 'helped',\n",
       " 'four',\n",
       " 'building',\n",
       " 'whether',\n",
       " 'saying',\n",
       " 'dogs',\n",
       " 'changed',\n",
       " '230',\n",
       " 'running',\n",
       " 'wearing',\n",
       " 'wrote',\n",
       " 'store',\n",
       " 'stand',\n",
       " 'plane',\n",
       " 'others',\n",
       " 'lie',\n",
       " 'order',\n",
       " 'maybe',\n",
       " 'sunday',\n",
       " 'stayed',\n",
       " 'speaks',\n",
       " 'showed',\n",
       " 'needed',\n",
       " 'girlfriend',\n",
       " 'famous',\n",
       " 'yours',\n",
       " 'asleep',\n",
       " 'advised',\n",
       " 'break',\n",
       " 'part',\n",
       " 'move',\n",
       " 'black',\n",
       " 'words',\n",
       " 'wheres',\n",
       " 'movies',\n",
       " 'ice',\n",
       " 'herself',\n",
       " 'beer',\n",
       " 'baseball',\n",
       " 'reason',\n",
       " 'lose',\n",
       " 'dress',\n",
       " 'become',\n",
       " 'anybody',\n",
       " 'real',\n",
       " 'key',\n",
       " 'expensive',\n",
       " 'dictionary',\n",
       " 'crazy',\n",
       " 'quit',\n",
       " 'piano',\n",
       " 'outside',\n",
       " 'hold',\n",
       " 'catch',\n",
       " 'team',\n",
       " 'strange',\n",
       " 'proud',\n",
       " 'noise',\n",
       " 'mistakes',\n",
       " 'interested',\n",
       " 'cup',\n",
       " 'business',\n",
       " 'between',\n",
       " 'sound',\n",
       " 'side',\n",
       " 'paper',\n",
       " 'paid',\n",
       " 'floor',\n",
       " 'exactly',\n",
       " 'during',\n",
       " 'different',\n",
       " 'agree',\n",
       " 'whole',\n",
       " 'speaking',\n",
       " 'quickly',\n",
       " 'least',\n",
       " 'glasses',\n",
       " 'enjoy',\n",
       " 'drunk',\n",
       " 'behind',\n",
       " 'worry',\n",
       " 'uncle',\n",
       " 'telephone',\n",
       " 'loved',\n",
       " 'known',\n",
       " 'head',\n",
       " 'front',\n",
       " 'send',\n",
       " 'rules',\n",
       " 'missed',\n",
       " 'dangerous',\n",
       " 'cook',\n",
       " 'choice',\n",
       " 'weight',\n",
       " 'swimming',\n",
       " 'road',\n",
       " 'library',\n",
       " 'glass',\n",
       " 'explain',\n",
       " 'evening',\n",
       " 'cats',\n",
       " 'broken',\n",
       " 'blame',\n",
       " 'bank',\n",
       " 'animals',\n",
       " 'walked',\n",
       " 'waited',\n",
       " 'united',\n",
       " 'somebody',\n",
       " 'seemed',\n",
       " 'restaurant',\n",
       " 'raining',\n",
       " 'poor',\n",
       " 'pain',\n",
       " 'ok',\n",
       " 'lucky',\n",
       " 'hell',\n",
       " 'women',\n",
       " 'strong',\n",
       " 'shirt',\n",
       " 'safe',\n",
       " 'lying',\n",
       " 'health',\n",
       " 'guitar',\n",
       " 'garden',\n",
       " 'brought',\n",
       " 'bag',\n",
       " 'win',\n",
       " 'trip',\n",
       " 'return',\n",
       " 'promise',\n",
       " 'prefer',\n",
       " 'hat',\n",
       " 'cry',\n",
       " 'concert',\n",
       " 'boys',\n",
       " 'visited',\n",
       " 'touch',\n",
       " 'television',\n",
       " 'takes',\n",
       " 'sun',\n",
       " 'problems',\n",
       " 'meat',\n",
       " 'learned',\n",
       " 'knife',\n",
       " 'heart',\n",
       " 'fine',\n",
       " 'wear',\n",
       " 'wall',\n",
       " 'hide',\n",
       " 'drinking',\n",
       " 'winter',\n",
       " 'twice',\n",
       " 'thanks',\n",
       " 'tall',\n",
       " 'radio',\n",
       " 'played',\n",
       " 'driving',\n",
       " 'cost',\n",
       " 'finally',\n",
       " 'feeling',\n",
       " 'decision',\n",
       " 'worried',\n",
       " 'won',\n",
       " 'thirty',\n",
       " 'talked',\n",
       " 'states',\n",
       " 'seven',\n",
       " 'expect',\n",
       " 'apple',\n",
       " 'younger',\n",
       " 'worse',\n",
       " 'smoke',\n",
       " 'seeing',\n",
       " 'probably',\n",
       " 'london',\n",
       " 'leaving',\n",
       " 'forward',\n",
       " 'attention',\n",
       " 'whose',\n",
       " 'kitchen',\n",
       " 'half',\n",
       " 'danger',\n",
       " 'waste',\n",
       " 'sent',\n",
       " 'sad',\n",
       " 'promised',\n",
       " 'pass',\n",
       " 'closed',\n",
       " 'arrive',\n",
       " 'air',\n",
       " 'terrible',\n",
       " 'situation',\n",
       " 'several',\n",
       " 'lawyer',\n",
       " 'patient',\n",
       " 'months',\n",
       " 'minute',\n",
       " 'husband',\n",
       " 'hed',\n",
       " 'guy',\n",
       " 'fishing',\n",
       " 'eggs',\n",
       " 'werent',\n",
       " 'weekend',\n",
       " 'ticket',\n",
       " 'soccer',\n",
       " 'point',\n",
       " 'opened',\n",
       " 'mountain',\n",
       " 'mad',\n",
       " 'either',\n",
       " 'desk',\n",
       " 'completely',\n",
       " 'china',\n",
       " 'accept',\n",
       " 'abroad',\n",
       " 'traffic',\n",
       " 'set',\n",
       " 'seat',\n",
       " 'less',\n",
       " 'learning',\n",
       " 'guess',\n",
       " 'girls',\n",
       " 'follow',\n",
       " 'airport',\n",
       " 'umbrella',\n",
       " 'solve',\n",
       " 'sleeping',\n",
       " 'opinion',\n",
       " 'happens',\n",
       " 'drank',\n",
       " 'dance',\n",
       " 'crying',\n",
       " 'blue',\n",
       " 'alive',\n",
       " 'wash',\n",
       " 'spoke',\n",
       " 'singing',\n",
       " 'ship',\n",
       " 'serious',\n",
       " 'kids',\n",
       " 'invited',\n",
       " 'beach',\n",
       " 'also',\n",
       " 'writing',\n",
       " 'vacation',\n",
       " 'taken',\n",
       " 'perfect',\n",
       " 'listening',\n",
       " 'liked',\n",
       " 'horse',\n",
       " 'hiding',\n",
       " 'fight',\n",
       " 'apples',\n",
       " 'walking',\n",
       " 'sitting',\n",
       " 'shut',\n",
       " 'shouldve',\n",
       " 'machine',\n",
       " 'excuse',\n",
       " 'brothers',\n",
       " 'address',\n",
       " 'across',\n",
       " 'written',\n",
       " 'travel',\n",
       " 'test',\n",
       " 'telling',\n",
       " 'medicine',\n",
       " 'kiss',\n",
       " 'easily',\n",
       " 'college',\n",
       " 'church',\n",
       " 'piece',\n",
       " 'passed',\n",
       " 'paris',\n",
       " 'message',\n",
       " 'itll',\n",
       " 'impossible',\n",
       " 'happening',\n",
       " 'grandfather',\n",
       " 'future',\n",
       " 'chair',\n",
       " 'case',\n",
       " 'begin',\n",
       " 'tie',\n",
       " 'slowly',\n",
       " 'pick',\n",
       " 'pen',\n",
       " 'offer',\n",
       " 'lake',\n",
       " 'hardly',\n",
       " 'boyfriend',\n",
       " 'bird',\n",
       " 'arm',\n",
       " 'wake',\n",
       " 'success',\n",
       " 'stolen',\n",
       " 'sense',\n",
       " 'second',\n",
       " 'none',\n",
       " 'laughed',\n",
       " 'heavy',\n",
       " 'carefully',\n",
       " 'boss',\n",
       " 'american',\n",
       " 'teach',\n",
       " 'suddenly',\n",
       " 'smart',\n",
       " 'shopping',\n",
       " 'failed',\n",
       " 'count',\n",
       " 'weeks',\n",
       " 'somewhere',\n",
       " 'past',\n",
       " 'lend',\n",
       " 'hundred',\n",
       " 'funny',\n",
       " 'doubt',\n",
       " 'coat',\n",
       " 'cars',\n",
       " 'worth',\n",
       " 'voice',\n",
       " 'smile',\n",
       " 'shot',\n",
       " 'refused',\n",
       " 'ought',\n",
       " 'mustve',\n",
       " 'means',\n",
       " 'figure',\n",
       " 'expected',\n",
       " 'eight',\n",
       " 'bread',\n",
       " 'bath',\n",
       " 'york',\n",
       " 'sky',\n",
       " 'pictures',\n",
       " 'nervous',\n",
       " 'law',\n",
       " 'keys',\n",
       " 'guys',\n",
       " 'france',\n",
       " 'fly',\n",
       " 'feed',\n",
       " 'fault',\n",
       " 'eats',\n",
       " 'correct',\n",
       " 'cooking',\n",
       " 'chinese',\n",
       " 'trees',\n",
       " 'though',\n",
       " 'inside',\n",
       " 'foreign',\n",
       " 'fat',\n",
       " 'enemy',\n",
       " 'cream',\n",
       " 'clear',\n",
       " 'choose',\n",
       " 'sign',\n",
       " 'leaves',\n",
       " 'gun',\n",
       " 'deal',\n",
       " 'standing',\n",
       " 'shop',\n",
       " 'salt',\n",
       " 'quiet',\n",
       " 'price',\n",
       " 'honest',\n",
       " 'foot',\n",
       " 'ball',\n",
       " 'yes',\n",
       " 'studied',\n",
       " 'staying',\n",
       " 'sounds',\n",
       " 'sell',\n",
       " 'ride',\n",
       " 'prison',\n",
       " 'novel',\n",
       " 'languages',\n",
       " 'entered',\n",
       " 'deep',\n",
       " 'carry',\n",
       " 'bridge',\n",
       " 'blood',\n",
       " 'birds',\n",
       " 'taxi',\n",
       " 'spoken',\n",
       " 'plans',\n",
       " 'locked',\n",
       " 'joke',\n",
       " 'given',\n",
       " 'anywhere',\n",
       " 'worst',\n",
       " 'whatever',\n",
       " 'watched',\n",
       " 'warm',\n",
       " 'till',\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_vocab = source_vectorizer.get_vocabulary()\n",
    "source_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8db41eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '',\n",
       " 1: '[UNK]',\n",
       " 2: 'the',\n",
       " 3: 'i',\n",
       " 4: 'to',\n",
       " 5: 'you',\n",
       " 6: 'tom',\n",
       " 7: 'a',\n",
       " 8: 'is',\n",
       " 9: 'he',\n",
       " 10: 'in',\n",
       " 11: 'of',\n",
       " 12: 'that',\n",
       " 13: 'it',\n",
       " 14: 'was',\n",
       " 15: 'do',\n",
       " 16: 'this',\n",
       " 17: 'have',\n",
       " 18: 'me',\n",
       " 19: 'my',\n",
       " 20: 'for',\n",
       " 21: 'she',\n",
       " 22: 'dont',\n",
       " 23: 'what',\n",
       " 24: 'are',\n",
       " 25: 'his',\n",
       " 26: 'mary',\n",
       " 27: 'we',\n",
       " 28: 'your',\n",
       " 29: 'on',\n",
       " 30: 'be',\n",
       " 31: 'want',\n",
       " 32: 'with',\n",
       " 33: 'not',\n",
       " 34: 'im',\n",
       " 35: 'and',\n",
       " 36: 'like',\n",
       " 37: 'at',\n",
       " 38: 'know',\n",
       " 39: 'him',\n",
       " 40: 'can',\n",
       " 41: 'go',\n",
       " 42: 'her',\n",
       " 43: 'has',\n",
       " 44: 'will',\n",
       " 45: 'there',\n",
       " 46: 'its',\n",
       " 47: 'time',\n",
       " 48: 'they',\n",
       " 49: 'as',\n",
       " 50: 'very',\n",
       " 51: 'how',\n",
       " 52: 'did',\n",
       " 53: 'were',\n",
       " 54: 'had',\n",
       " 55: 'all',\n",
       " 56: 'here',\n",
       " 57: 'about',\n",
       " 58: 'up',\n",
       " 59: 'didnt',\n",
       " 60: 'think',\n",
       " 61: 'get',\n",
       " 62: 'out',\n",
       " 63: 'when',\n",
       " 64: 'from',\n",
       " 65: 'cant',\n",
       " 66: 'if',\n",
       " 67: 'an',\n",
       " 68: 'no',\n",
       " 69: 'one',\n",
       " 70: 'going',\n",
       " 71: 'doesnt',\n",
       " 72: 'would',\n",
       " 73: 'by',\n",
       " 74: 'see',\n",
       " 75: 'why',\n",
       " 76: 'come',\n",
       " 77: 'good',\n",
       " 78: 'ill',\n",
       " 79: 'please',\n",
       " 80: 'just',\n",
       " 81: 'youre',\n",
       " 82: 'who',\n",
       " 83: 'so',\n",
       " 84: 'need',\n",
       " 85: 'been',\n",
       " 86: 'help',\n",
       " 87: 'more',\n",
       " 88: 'tell',\n",
       " 89: 'now',\n",
       " 90: 'but',\n",
       " 91: 'where',\n",
       " 92: 'than',\n",
       " 93: 'never',\n",
       " 94: 'am',\n",
       " 95: 'too',\n",
       " 96: 'got',\n",
       " 97: 'some',\n",
       " 98: 'much',\n",
       " 99: 'last',\n",
       " 100: 'us',\n",
       " 101: 'something',\n",
       " 102: 'car',\n",
       " 103: 'take',\n",
       " 104: 'money',\n",
       " 105: 'day',\n",
       " 106: 'should',\n",
       " 107: 'could',\n",
       " 108: 'ive',\n",
       " 109: 'home',\n",
       " 110: 'work',\n",
       " 111: 'well',\n",
       " 112: 'people',\n",
       " 113: 'back',\n",
       " 114: 'went',\n",
       " 115: 'told',\n",
       " 116: 'many',\n",
       " 117: 'our',\n",
       " 118: 'house',\n",
       " 119: 'book',\n",
       " 120: 'really',\n",
       " 121: 'hes',\n",
       " 122: 'does',\n",
       " 123: 'any',\n",
       " 124: 'said',\n",
       " 125: 'lot',\n",
       " 126: 'anything',\n",
       " 127: 'two',\n",
       " 128: 'only',\n",
       " 129: 'say',\n",
       " 130: 'always',\n",
       " 131: 'make',\n",
       " 132: 'school',\n",
       " 133: 'eat',\n",
       " 134: 'isnt',\n",
       " 135: 'give',\n",
       " 136: 'new',\n",
       " 137: 'today',\n",
       " 138: 'made',\n",
       " 139: 'room',\n",
       " 140: 'thought',\n",
       " 141: 'thats',\n",
       " 142: 'french',\n",
       " 143: 'right',\n",
       " 144: 'must',\n",
       " 145: 'speak',\n",
       " 146: 'toms',\n",
       " 147: 'long',\n",
       " 148: 'old',\n",
       " 149: 'love',\n",
       " 150: 'father',\n",
       " 151: 'look',\n",
       " 152: 'man',\n",
       " 153: 'lets',\n",
       " 154: 'every',\n",
       " 155: 'let',\n",
       " 156: 'three',\n",
       " 157: 'night',\n",
       " 158: 'still',\n",
       " 159: 'tomorrow',\n",
       " 160: 'before',\n",
       " 161: 'asked',\n",
       " 162: 'wanted',\n",
       " 163: 'talk',\n",
       " 164: 'boston',\n",
       " 165: 'off',\n",
       " 166: 'id',\n",
       " 167: 'left',\n",
       " 168: 'little',\n",
       " 169: 'put',\n",
       " 170: 'dog',\n",
       " 171: 'way',\n",
       " 172: 'whats',\n",
       " 173: 'or',\n",
       " 174: 'again',\n",
       " 175: 'nothing',\n",
       " 176: 'into',\n",
       " 177: 'may',\n",
       " 178: 'leave',\n",
       " 179: 'after',\n",
       " 180: 'yesterday',\n",
       " 181: 'years',\n",
       " 182: 'saw',\n",
       " 183: 'job',\n",
       " 184: 'over',\n",
       " 185: 'live',\n",
       " 186: 'english',\n",
       " 187: 'better',\n",
       " 188: 'stay',\n",
       " 189: 'came',\n",
       " 190: 'wont',\n",
       " 191: 'first',\n",
       " 192: 'down',\n",
       " 193: 'everything',\n",
       " 194: 'buy',\n",
       " 195: 'play',\n",
       " 196: 'mother',\n",
       " 197: 'read',\n",
       " 198: 'them',\n",
       " 199: 'other',\n",
       " 200: 'happy',\n",
       " 201: 'next',\n",
       " 202: 'life',\n",
       " 203: 'theres',\n",
       " 204: 'find',\n",
       " 205: 'wants',\n",
       " 206: 'children',\n",
       " 207: 'stop',\n",
       " 208: 'took',\n",
       " 209: 'couldnt',\n",
       " 210: 'ask',\n",
       " 211: 'these',\n",
       " 212: 'call',\n",
       " 213: 'understand',\n",
       " 214: 'bought',\n",
       " 215: 'morning',\n",
       " 216: 'friends',\n",
       " 217: 'believe',\n",
       " 218: 'away',\n",
       " 219: 'their',\n",
       " 220: 'doing',\n",
       " 221: 'keep',\n",
       " 222: 'problem',\n",
       " 223: 'feel',\n",
       " 224: 'used',\n",
       " 225: 'door',\n",
       " 226: 'ever',\n",
       " 227: 'lost',\n",
       " 228: 'late',\n",
       " 229: 'hard',\n",
       " 230: 'gave',\n",
       " 231: 'happened',\n",
       " 232: 'already',\n",
       " 233: 'sure',\n",
       " 234: 'year',\n",
       " 235: 'soon',\n",
       " 236: 'without',\n",
       " 237: 'enough',\n",
       " 238: 'wrong',\n",
       " 239: 'remember',\n",
       " 240: 'best',\n",
       " 241: 'water',\n",
       " 242: 'married',\n",
       " 243: 'friend',\n",
       " 244: 'even',\n",
       " 245: 'things',\n",
       " 246: 'because',\n",
       " 247: 'bad',\n",
       " 248: 'marys',\n",
       " 249: 'busy',\n",
       " 250: 'wasnt',\n",
       " 251: 'knows',\n",
       " 252: 'hear',\n",
       " 253: 'alone',\n",
       " 254: 'thing',\n",
       " 255: 'beautiful',\n",
       " 256: 'wait',\n",
       " 257: 'often',\n",
       " 258: 'likes',\n",
       " 259: 'bed',\n",
       " 260: 'looking',\n",
       " 261: 'week',\n",
       " 262: 'name',\n",
       " 263: 'party',\n",
       " 264: 'heard',\n",
       " 265: 'found',\n",
       " 266: 'try',\n",
       " 267: 'teacher',\n",
       " 268: 'done',\n",
       " 269: 'able',\n",
       " 270: 'same',\n",
       " 271: 'seen',\n",
       " 272: 'theyre',\n",
       " 273: 'train',\n",
       " 274: 'idea',\n",
       " 275: 'looks',\n",
       " 276: 'food',\n",
       " 277: 'cold',\n",
       " 278: 'big',\n",
       " 279: 'boy',\n",
       " 280: 'tired',\n",
       " 281: 'answer',\n",
       " 282: 'john',\n",
       " 283: 'true',\n",
       " 284: 'coffee',\n",
       " 285: 'around',\n",
       " 286: 'brother',\n",
       " 287: 'being',\n",
       " 288: 'knew',\n",
       " 289: 'drink',\n",
       " 290: 'watch',\n",
       " 291: 'person',\n",
       " 292: 'use',\n",
       " 293: 'learn',\n",
       " 294: 'everyone',\n",
       " 295: 'shes',\n",
       " 296: 'wish',\n",
       " 297: 'open',\n",
       " 298: 'died',\n",
       " 299: 'while',\n",
       " 300: 'bus',\n",
       " 301: 'which',\n",
       " 302: 'letter',\n",
       " 303: 'hope',\n",
       " 304: 'books',\n",
       " 305: 'another',\n",
       " 306: 'met',\n",
       " 307: 'almost',\n",
       " 308: 'study',\n",
       " 309: 'someone',\n",
       " 310: 'days',\n",
       " 311: 'young',\n",
       " 312: 'anyone',\n",
       " 313: 'yet',\n",
       " 314: 'world',\n",
       " 315: 'mind',\n",
       " 316: 'monday',\n",
       " 317: 'youll',\n",
       " 318: 'doctor',\n",
       " 319: 'those',\n",
       " 320: 'japan',\n",
       " 321: 'each',\n",
       " 322: 'talking',\n",
       " 323: 'girl',\n",
       " 324: 'parents',\n",
       " 325: 'truth',\n",
       " 326: 'sleep',\n",
       " 327: 'pay',\n",
       " 328: 'place',\n",
       " 329: 'walk',\n",
       " 330: 'seems',\n",
       " 331: 'lunch',\n",
       " 332: 'kind',\n",
       " 333: 'happen',\n",
       " 334: 'few',\n",
       " 335: 'sister',\n",
       " 336: 'both',\n",
       " 337: 'turn',\n",
       " 338: 'most',\n",
       " 339: 'family',\n",
       " 340: 'once',\n",
       " 341: 'care',\n",
       " 342: 'write',\n",
       " 343: 'early',\n",
       " 344: 'havent',\n",
       " 345: 'difficult',\n",
       " 346: 'looked',\n",
       " 347: 'getting',\n",
       " 348: 'ten',\n",
       " 349: 'own',\n",
       " 350: 'great',\n",
       " 351: 'dinner',\n",
       " 352: 'tried',\n",
       " 353: 'angry',\n",
       " 354: 'together',\n",
       " 355: 'until',\n",
       " 356: 'plan',\n",
       " 357: 'wouldnt',\n",
       " 358: 'coming',\n",
       " 359: 'tv',\n",
       " 360: 'else',\n",
       " 361: 'rain',\n",
       " 362: 'arent',\n",
       " 363: 'afraid',\n",
       " 364: 'nobody',\n",
       " 365: 'himself',\n",
       " 366: 'youve',\n",
       " 367: 'yourself',\n",
       " 368: 'favorite',\n",
       " 369: 'country',\n",
       " 370: 'waiting',\n",
       " 371: 'since',\n",
       " 372: 'cat',\n",
       " 373: 'mine',\n",
       " 374: 'table',\n",
       " 375: 'child',\n",
       " 376: 'show',\n",
       " 377: 'ago',\n",
       " 378: 'hand',\n",
       " 379: 'says',\n",
       " 380: 'matter',\n",
       " 381: 'lives',\n",
       " 382: 'five',\n",
       " 383: 'eating',\n",
       " 384: 'trying',\n",
       " 385: 'police',\n",
       " 386: 'wife',\n",
       " 387: 'reading',\n",
       " 388: 'phone',\n",
       " 389: 'such',\n",
       " 390: 'question',\n",
       " 391: 'hurt',\n",
       " 392: 'ready',\n",
       " 393: 'hours',\n",
       " 394: 'playing',\n",
       " 395: 'meet',\n",
       " 396: 'ate',\n",
       " 397: 'everybody',\n",
       " 398: 'drive',\n",
       " 399: 'accident',\n",
       " 400: 'swim',\n",
       " 401: 'meeting',\n",
       " 402: 'myself',\n",
       " 403: 'hate',\n",
       " 404: 'sick',\n",
       " 405: 'might',\n",
       " 406: 'usually',\n",
       " 407: 'tonight',\n",
       " 408: 'finished',\n",
       " 409: 'sorry',\n",
       " 410: 'nice',\n",
       " 411: 'small',\n",
       " 412: 'office',\n",
       " 413: 'month',\n",
       " 414: 'start',\n",
       " 415: 'minutes',\n",
       " 416: 'decided',\n",
       " 417: 'window',\n",
       " 418: 'story',\n",
       " 419: 'important',\n",
       " 420: 'far',\n",
       " 421: 'trouble',\n",
       " 422: 'started',\n",
       " 423: 'japanese',\n",
       " 424: 'ran',\n",
       " 425: 'having',\n",
       " 426: 'easy',\n",
       " 427: 'word',\n",
       " 428: 'times',\n",
       " 429: 'shouldnt',\n",
       " 430: 'park',\n",
       " 431: 'city',\n",
       " 432: 'arrived',\n",
       " 433: 'station',\n",
       " 434: 'called',\n",
       " 435: 'woman',\n",
       " 436: 'goes',\n",
       " 437: 'felt',\n",
       " 438: 'shoes',\n",
       " 439: 'needs',\n",
       " 440: 'music',\n",
       " 441: 'broke',\n",
       " 442: 'under',\n",
       " 443: 'working',\n",
       " 444: 'son',\n",
       " 445: 'stupid',\n",
       " 446: 'homework',\n",
       " 447: 'fire',\n",
       " 448: 'anymore',\n",
       " 449: 'students',\n",
       " 450: 'town',\n",
       " 451: 'mistake',\n",
       " 452: 'movie',\n",
       " 453: 'gone',\n",
       " 454: 'fast',\n",
       " 455: 'tennis',\n",
       " 456: 'pretty',\n",
       " 457: 'game',\n",
       " 458: 'quite',\n",
       " 459: 'hot',\n",
       " 460: 'song',\n",
       " 461: 'red',\n",
       " 462: 'thank',\n",
       " 463: 'fun',\n",
       " 464: 'eyes',\n",
       " 465: 'run',\n",
       " 466: 'christmas',\n",
       " 467: 'change',\n",
       " 468: 'rich',\n",
       " 469: 'cake',\n",
       " 470: 'studying',\n",
       " 471: 'six',\n",
       " 472: 'lived',\n",
       " 473: 'against',\n",
       " 474: 'visit',\n",
       " 475: 'then',\n",
       " 476: 'number',\n",
       " 477: 'comes',\n",
       " 478: 'bring',\n",
       " 479: 'afternoon',\n",
       " 480: 'picture',\n",
       " 481: 'australia',\n",
       " 482: 'river',\n",
       " 483: 'language',\n",
       " 484: 'forget',\n",
       " 485: 'spend',\n",
       " 486: 'present',\n",
       " 487: 'breakfast',\n",
       " 488: 'turned',\n",
       " 489: 'large',\n",
       " 490: 'weather',\n",
       " 491: 'smoking',\n",
       " 492: 'listen',\n",
       " 493: 'end',\n",
       " 494: 'close',\n",
       " 495: 'summer',\n",
       " 496: 'makes',\n",
       " 497: 'caught',\n",
       " 498: 'advice',\n",
       " 499: 'longer',\n",
       " 500: 'fell',\n",
       " 501: 'along',\n",
       " 502: 'watching',\n",
       " 503: 'sit',\n",
       " 504: 'milk',\n",
       " 505: 'finish',\n",
       " 506: 'began',\n",
       " 507: 'weve',\n",
       " 508: 'kept',\n",
       " 509: 'fish',\n",
       " 510: 'war',\n",
       " 511: 'hands',\n",
       " 512: 'men',\n",
       " 513: 'mean',\n",
       " 514: 'face',\n",
       " 515: 'dream',\n",
       " 516: 'class',\n",
       " 517: 'surprised',\n",
       " 518: 'loves',\n",
       " 519: 'kill',\n",
       " 520: 'interesting',\n",
       " 521: 'tree',\n",
       " 522: 'taking',\n",
       " 523: 'snow',\n",
       " 524: 'born',\n",
       " 525: 'wonder',\n",
       " 526: 'through',\n",
       " 527: 'box',\n",
       " 528: 'baby',\n",
       " 529: 'youd',\n",
       " 530: 'making',\n",
       " 531: 'hair',\n",
       " 532: 'die',\n",
       " 533: 'camera',\n",
       " 534: 'works',\n",
       " 535: 'older',\n",
       " 536: 'near',\n",
       " 537: 'hotel',\n",
       " 538: 'sometimes',\n",
       " 539: 'rather',\n",
       " 540: 'full',\n",
       " 541: 'trust',\n",
       " 542: 'street',\n",
       " 543: 'secret',\n",
       " 544: 'miss',\n",
       " 545: 'light',\n",
       " 546: 'hurry',\n",
       " 547: 'free',\n",
       " 548: 'death',\n",
       " 549: 'became',\n",
       " 550: 'whos',\n",
       " 551: 'living',\n",
       " 552: 'hour',\n",
       " 553: 'cut',\n",
       " 554: 'short',\n",
       " 555: 'dark',\n",
       " 556: 'student',\n",
       " 557: 'spent',\n",
       " 558: 'seem',\n",
       " 559: 'news',\n",
       " 560: 'later',\n",
       " 561: 'hospital',\n",
       " 562: 'cannot',\n",
       " 563: 'birthday',\n",
       " 564: 'stopped',\n",
       " 565: 'hungry',\n",
       " 566: 'dollars',\n",
       " 567: 'thinks',\n",
       " 568: 'thinking',\n",
       " 569: 'company',\n",
       " 570: 'clean',\n",
       " 571: 'bicycle',\n",
       " 572: 'america',\n",
       " 573: 'wine',\n",
       " 574: 'sat',\n",
       " 575: 'rest',\n",
       " 576: 'questions',\n",
       " 577: 'gets',\n",
       " 578: 'age',\n",
       " 579: 'white',\n",
       " 580: 'oclock',\n",
       " 581: 'killed',\n",
       " 582: 'hit',\n",
       " 583: 'hasnt',\n",
       " 584: 'computer',\n",
       " 585: 'chance',\n",
       " 586: 'careful',\n",
       " 587: 'canadian',\n",
       " 588: 'bit',\n",
       " 589: 'tokyo',\n",
       " 590: 'forgot',\n",
       " 591: 'eaten',\n",
       " 592: 'clothes',\n",
       " 593: 'tea',\n",
       " 594: 'glad',\n",
       " 595: 'flowers',\n",
       " 596: 'daughter',\n",
       " 597: 'possible',\n",
       " 598: 'moment',\n",
       " 599: 'high',\n",
       " 600: 'dead',\n",
       " 601: 'worked',\n",
       " 602: 'sing',\n",
       " 603: 'helped',\n",
       " 604: 'four',\n",
       " 605: 'building',\n",
       " 606: 'whether',\n",
       " 607: 'saying',\n",
       " 608: 'dogs',\n",
       " 609: 'changed',\n",
       " 610: '230',\n",
       " 611: 'running',\n",
       " 612: 'wearing',\n",
       " 613: 'wrote',\n",
       " 614: 'store',\n",
       " 615: 'stand',\n",
       " 616: 'plane',\n",
       " 617: 'others',\n",
       " 618: 'lie',\n",
       " 619: 'order',\n",
       " 620: 'maybe',\n",
       " 621: 'sunday',\n",
       " 622: 'stayed',\n",
       " 623: 'speaks',\n",
       " 624: 'showed',\n",
       " 625: 'needed',\n",
       " 626: 'girlfriend',\n",
       " 627: 'famous',\n",
       " 628: 'yours',\n",
       " 629: 'asleep',\n",
       " 630: 'advised',\n",
       " 631: 'break',\n",
       " 632: 'part',\n",
       " 633: 'move',\n",
       " 634: 'black',\n",
       " 635: 'words',\n",
       " 636: 'wheres',\n",
       " 637: 'movies',\n",
       " 638: 'ice',\n",
       " 639: 'herself',\n",
       " 640: 'beer',\n",
       " 641: 'baseball',\n",
       " 642: 'reason',\n",
       " 643: 'lose',\n",
       " 644: 'dress',\n",
       " 645: 'become',\n",
       " 646: 'anybody',\n",
       " 647: 'real',\n",
       " 648: 'key',\n",
       " 649: 'expensive',\n",
       " 650: 'dictionary',\n",
       " 651: 'crazy',\n",
       " 652: 'quit',\n",
       " 653: 'piano',\n",
       " 654: 'outside',\n",
       " 655: 'hold',\n",
       " 656: 'catch',\n",
       " 657: 'team',\n",
       " 658: 'strange',\n",
       " 659: 'proud',\n",
       " 660: 'noise',\n",
       " 661: 'mistakes',\n",
       " 662: 'interested',\n",
       " 663: 'cup',\n",
       " 664: 'business',\n",
       " 665: 'between',\n",
       " 666: 'sound',\n",
       " 667: 'side',\n",
       " 668: 'paper',\n",
       " 669: 'paid',\n",
       " 670: 'floor',\n",
       " 671: 'exactly',\n",
       " 672: 'during',\n",
       " 673: 'different',\n",
       " 674: 'agree',\n",
       " 675: 'whole',\n",
       " 676: 'speaking',\n",
       " 677: 'quickly',\n",
       " 678: 'least',\n",
       " 679: 'glasses',\n",
       " 680: 'enjoy',\n",
       " 681: 'drunk',\n",
       " 682: 'behind',\n",
       " 683: 'worry',\n",
       " 684: 'uncle',\n",
       " 685: 'telephone',\n",
       " 686: 'loved',\n",
       " 687: 'known',\n",
       " 688: 'head',\n",
       " 689: 'front',\n",
       " 690: 'send',\n",
       " 691: 'rules',\n",
       " 692: 'missed',\n",
       " 693: 'dangerous',\n",
       " 694: 'cook',\n",
       " 695: 'choice',\n",
       " 696: 'weight',\n",
       " 697: 'swimming',\n",
       " 698: 'road',\n",
       " 699: 'library',\n",
       " 700: 'glass',\n",
       " 701: 'explain',\n",
       " 702: 'evening',\n",
       " 703: 'cats',\n",
       " 704: 'broken',\n",
       " 705: 'blame',\n",
       " 706: 'bank',\n",
       " 707: 'animals',\n",
       " 708: 'walked',\n",
       " 709: 'waited',\n",
       " 710: 'united',\n",
       " 711: 'somebody',\n",
       " 712: 'seemed',\n",
       " 713: 'restaurant',\n",
       " 714: 'raining',\n",
       " 715: 'poor',\n",
       " 716: 'pain',\n",
       " 717: 'ok',\n",
       " 718: 'lucky',\n",
       " 719: 'hell',\n",
       " 720: 'women',\n",
       " 721: 'strong',\n",
       " 722: 'shirt',\n",
       " 723: 'safe',\n",
       " 724: 'lying',\n",
       " 725: 'health',\n",
       " 726: 'guitar',\n",
       " 727: 'garden',\n",
       " 728: 'brought',\n",
       " 729: 'bag',\n",
       " 730: 'win',\n",
       " 731: 'trip',\n",
       " 732: 'return',\n",
       " 733: 'promise',\n",
       " 734: 'prefer',\n",
       " 735: 'hat',\n",
       " 736: 'cry',\n",
       " 737: 'concert',\n",
       " 738: 'boys',\n",
       " 739: 'visited',\n",
       " 740: 'touch',\n",
       " 741: 'television',\n",
       " 742: 'takes',\n",
       " 743: 'sun',\n",
       " 744: 'problems',\n",
       " 745: 'meat',\n",
       " 746: 'learned',\n",
       " 747: 'knife',\n",
       " 748: 'heart',\n",
       " 749: 'fine',\n",
       " 750: 'wear',\n",
       " 751: 'wall',\n",
       " 752: 'hide',\n",
       " 753: 'drinking',\n",
       " 754: 'winter',\n",
       " 755: 'twice',\n",
       " 756: 'thanks',\n",
       " 757: 'tall',\n",
       " 758: 'radio',\n",
       " 759: 'played',\n",
       " 760: 'driving',\n",
       " 761: 'cost',\n",
       " 762: 'finally',\n",
       " 763: 'feeling',\n",
       " 764: 'decision',\n",
       " 765: 'worried',\n",
       " 766: 'won',\n",
       " 767: 'thirty',\n",
       " 768: 'talked',\n",
       " 769: 'states',\n",
       " 770: 'seven',\n",
       " 771: 'expect',\n",
       " 772: 'apple',\n",
       " 773: 'younger',\n",
       " 774: 'worse',\n",
       " 775: 'smoke',\n",
       " 776: 'seeing',\n",
       " 777: 'probably',\n",
       " 778: 'london',\n",
       " 779: 'leaving',\n",
       " 780: 'forward',\n",
       " 781: 'attention',\n",
       " 782: 'whose',\n",
       " 783: 'kitchen',\n",
       " 784: 'half',\n",
       " 785: 'danger',\n",
       " 786: 'waste',\n",
       " 787: 'sent',\n",
       " 788: 'sad',\n",
       " 789: 'promised',\n",
       " 790: 'pass',\n",
       " 791: 'closed',\n",
       " 792: 'arrive',\n",
       " 793: 'air',\n",
       " 794: 'terrible',\n",
       " 795: 'situation',\n",
       " 796: 'several',\n",
       " 797: 'lawyer',\n",
       " 798: 'patient',\n",
       " 799: 'months',\n",
       " 800: 'minute',\n",
       " 801: 'husband',\n",
       " 802: 'hed',\n",
       " 803: 'guy',\n",
       " 804: 'fishing',\n",
       " 805: 'eggs',\n",
       " 806: 'werent',\n",
       " 807: 'weekend',\n",
       " 808: 'ticket',\n",
       " 809: 'soccer',\n",
       " 810: 'point',\n",
       " 811: 'opened',\n",
       " 812: 'mountain',\n",
       " 813: 'mad',\n",
       " 814: 'either',\n",
       " 815: 'desk',\n",
       " 816: 'completely',\n",
       " 817: 'china',\n",
       " 818: 'accept',\n",
       " 819: 'abroad',\n",
       " 820: 'traffic',\n",
       " 821: 'set',\n",
       " 822: 'seat',\n",
       " 823: 'less',\n",
       " 824: 'learning',\n",
       " 825: 'guess',\n",
       " 826: 'girls',\n",
       " 827: 'follow',\n",
       " 828: 'airport',\n",
       " 829: 'umbrella',\n",
       " 830: 'solve',\n",
       " 831: 'sleeping',\n",
       " 832: 'opinion',\n",
       " 833: 'happens',\n",
       " 834: 'drank',\n",
       " 835: 'dance',\n",
       " 836: 'crying',\n",
       " 837: 'blue',\n",
       " 838: 'alive',\n",
       " 839: 'wash',\n",
       " 840: 'spoke',\n",
       " 841: 'singing',\n",
       " 842: 'ship',\n",
       " 843: 'serious',\n",
       " 844: 'kids',\n",
       " 845: 'invited',\n",
       " 846: 'beach',\n",
       " 847: 'also',\n",
       " 848: 'writing',\n",
       " 849: 'vacation',\n",
       " 850: 'taken',\n",
       " 851: 'perfect',\n",
       " 852: 'listening',\n",
       " 853: 'liked',\n",
       " 854: 'horse',\n",
       " 855: 'hiding',\n",
       " 856: 'fight',\n",
       " 857: 'apples',\n",
       " 858: 'walking',\n",
       " 859: 'sitting',\n",
       " 860: 'shut',\n",
       " 861: 'shouldve',\n",
       " 862: 'machine',\n",
       " 863: 'excuse',\n",
       " 864: 'brothers',\n",
       " 865: 'address',\n",
       " 866: 'across',\n",
       " 867: 'written',\n",
       " 868: 'travel',\n",
       " 869: 'test',\n",
       " 870: 'telling',\n",
       " 871: 'medicine',\n",
       " 872: 'kiss',\n",
       " 873: 'easily',\n",
       " 874: 'college',\n",
       " 875: 'church',\n",
       " 876: 'piece',\n",
       " 877: 'passed',\n",
       " 878: 'paris',\n",
       " 879: 'message',\n",
       " 880: 'itll',\n",
       " 881: 'impossible',\n",
       " 882: 'happening',\n",
       " 883: 'grandfather',\n",
       " 884: 'future',\n",
       " 885: 'chair',\n",
       " 886: 'case',\n",
       " 887: 'begin',\n",
       " 888: 'tie',\n",
       " 889: 'slowly',\n",
       " 890: 'pick',\n",
       " 891: 'pen',\n",
       " 892: 'offer',\n",
       " 893: 'lake',\n",
       " 894: 'hardly',\n",
       " 895: 'boyfriend',\n",
       " 896: 'bird',\n",
       " 897: 'arm',\n",
       " 898: 'wake',\n",
       " 899: 'success',\n",
       " 900: 'stolen',\n",
       " 901: 'sense',\n",
       " 902: 'second',\n",
       " 903: 'none',\n",
       " 904: 'laughed',\n",
       " 905: 'heavy',\n",
       " 906: 'carefully',\n",
       " 907: 'boss',\n",
       " 908: 'american',\n",
       " 909: 'teach',\n",
       " 910: 'suddenly',\n",
       " 911: 'smart',\n",
       " 912: 'shopping',\n",
       " 913: 'failed',\n",
       " 914: 'count',\n",
       " 915: 'weeks',\n",
       " 916: 'somewhere',\n",
       " 917: 'past',\n",
       " 918: 'lend',\n",
       " 919: 'hundred',\n",
       " 920: 'funny',\n",
       " 921: 'doubt',\n",
       " 922: 'coat',\n",
       " 923: 'cars',\n",
       " 924: 'worth',\n",
       " 925: 'voice',\n",
       " 926: 'smile',\n",
       " 927: 'shot',\n",
       " 928: 'refused',\n",
       " 929: 'ought',\n",
       " 930: 'mustve',\n",
       " 931: 'means',\n",
       " 932: 'figure',\n",
       " 933: 'expected',\n",
       " 934: 'eight',\n",
       " 935: 'bread',\n",
       " 936: 'bath',\n",
       " 937: 'york',\n",
       " 938: 'sky',\n",
       " 939: 'pictures',\n",
       " 940: 'nervous',\n",
       " 941: 'law',\n",
       " 942: 'keys',\n",
       " 943: 'guys',\n",
       " 944: 'france',\n",
       " 945: 'fly',\n",
       " 946: 'feed',\n",
       " 947: 'fault',\n",
       " 948: 'eats',\n",
       " 949: 'correct',\n",
       " 950: 'cooking',\n",
       " 951: 'chinese',\n",
       " 952: 'trees',\n",
       " 953: 'though',\n",
       " 954: 'inside',\n",
       " 955: 'foreign',\n",
       " 956: 'fat',\n",
       " 957: 'enemy',\n",
       " 958: 'cream',\n",
       " 959: 'clear',\n",
       " 960: 'choose',\n",
       " 961: 'sign',\n",
       " 962: 'leaves',\n",
       " 963: 'gun',\n",
       " 964: 'deal',\n",
       " 965: 'standing',\n",
       " 966: 'shop',\n",
       " 967: 'salt',\n",
       " 968: 'quiet',\n",
       " 969: 'price',\n",
       " 970: 'honest',\n",
       " 971: 'foot',\n",
       " 972: 'ball',\n",
       " 973: 'yes',\n",
       " 974: 'studied',\n",
       " 975: 'staying',\n",
       " 976: 'sounds',\n",
       " 977: 'sell',\n",
       " 978: 'ride',\n",
       " 979: 'prison',\n",
       " 980: 'novel',\n",
       " 981: 'languages',\n",
       " 982: 'entered',\n",
       " 983: 'deep',\n",
       " 984: 'carry',\n",
       " 985: 'bridge',\n",
       " 986: 'blood',\n",
       " 987: 'birds',\n",
       " 988: 'taxi',\n",
       " 989: 'spoken',\n",
       " 990: 'plans',\n",
       " 991: 'locked',\n",
       " 992: 'joke',\n",
       " 993: 'given',\n",
       " 994: 'anywhere',\n",
       " 995: 'worst',\n",
       " 996: 'whatever',\n",
       " 997: 'watched',\n",
       " 998: 'warm',\n",
       " 999: 'till',\n",
       " ...}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_index = {i:word for i,word in enumerate(source_vocab)}\n",
    "source_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "074179c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " '[start]',\n",
       " '[end]',\n",
       " 'de',\n",
       " 'que',\n",
       " 'a',\n",
       " 'no',\n",
       " 'tom',\n",
       " 'la',\n",
       " 'el',\n",
       " 'en',\n",
       " 'es',\n",
       " 'un',\n",
       " 'me',\n",
       " 'se',\n",
       " 'por',\n",
       " 'lo',\n",
       " 'una',\n",
       " 'Él',\n",
       " 'su',\n",
       " 'está',\n",
       " 'los',\n",
       " 'mi',\n",
       " 'con',\n",
       " 'le',\n",
       " 'ella',\n",
       " 'qué',\n",
       " 'te',\n",
       " 'para',\n",
       " 'mary',\n",
       " 'las',\n",
       " 'y',\n",
       " 'más',\n",
       " 'al',\n",
       " 'yo',\n",
       " 'tu',\n",
       " 'estoy',\n",
       " 'muy',\n",
       " 'eso',\n",
       " 'tiene',\n",
       " 'esta',\n",
       " 'este',\n",
       " 'del',\n",
       " 'quiero',\n",
       " 'él',\n",
       " 'estaba',\n",
       " 'tengo',\n",
       " 'fue',\n",
       " 'si',\n",
       " 'aquí',\n",
       " 'casa',\n",
       " 'hacer',\n",
       " 'como',\n",
       " 'puedo',\n",
       " 'esto',\n",
       " 'algo',\n",
       " 'todo',\n",
       " 'hay',\n",
       " 'tiempo',\n",
       " 'ha',\n",
       " 'gusta',\n",
       " 'tan',\n",
       " 'son',\n",
       " 'todos',\n",
       " 'favor',\n",
       " 'ir',\n",
       " 'nada',\n",
       " 'puede',\n",
       " 'era',\n",
       " 'vez',\n",
       " 'bien',\n",
       " 'cuando',\n",
       " 'he',\n",
       " 'mucho',\n",
       " 'solo',\n",
       " 'ellos',\n",
       " 'sé',\n",
       " 'nos',\n",
       " 'mañana',\n",
       " 'nunca',\n",
       " 'dos',\n",
       " 'ser',\n",
       " 'creo',\n",
       " 'ya',\n",
       " 'dónde',\n",
       " 'sus',\n",
       " 'dinero',\n",
       " 'trabajo',\n",
       " 'cómo',\n",
       " 'dijo',\n",
       " 'ahora',\n",
       " 'estás',\n",
       " 'quién',\n",
       " 'hablar',\n",
       " 'tienes',\n",
       " 'pero',\n",
       " 'tomás',\n",
       " 'están',\n",
       " 'siempre',\n",
       " 'ese',\n",
       " 'soy',\n",
       " 'día',\n",
       " 'tú',\n",
       " 'puedes',\n",
       " 'voy',\n",
       " 'libro',\n",
       " 'había',\n",
       " 'hace',\n",
       " 'hoy',\n",
       " 'verdad',\n",
       " 'nadie',\n",
       " 'poco',\n",
       " 'quiere',\n",
       " 'esa',\n",
       " 'sabe',\n",
       " 'estar',\n",
       " 'ver',\n",
       " 'va',\n",
       " 'mejor',\n",
       " 'años',\n",
       " 'has',\n",
       " 'demasiado',\n",
       " 'quieres',\n",
       " 'padre',\n",
       " 'francés',\n",
       " 'antes',\n",
       " 'tarde',\n",
       " 'eres',\n",
       " 'mis',\n",
       " 'quería',\n",
       " 'maría',\n",
       " 'hizo',\n",
       " 'tenía',\n",
       " 'usted',\n",
       " 'parece',\n",
       " 'tres',\n",
       " 'hora',\n",
       " 'noche',\n",
       " 'boston',\n",
       " 'o',\n",
       " 'sobre',\n",
       " 'sin',\n",
       " 'haber',\n",
       " 'ayer',\n",
       " 'hasta',\n",
       " 'perro',\n",
       " 'mí',\n",
       " 'hombre',\n",
       " 'necesito',\n",
       " 'alguien',\n",
       " 'vida',\n",
       " 'inglés',\n",
       " 'todavía',\n",
       " 'estado',\n",
       " 'cuál',\n",
       " 'comer',\n",
       " 'cuándo',\n",
       " 'nuevo',\n",
       " 'hecho',\n",
       " 'días',\n",
       " 'tenemos',\n",
       " 'madre',\n",
       " 'coche',\n",
       " 'mismo',\n",
       " 'decir',\n",
       " 'nosotros',\n",
       " 'así',\n",
       " 'problema',\n",
       " 'gustaría',\n",
       " 'gente',\n",
       " 'pensé',\n",
       " 'otra',\n",
       " 'semana',\n",
       " 'tus',\n",
       " 'estamos',\n",
       " 'ti',\n",
       " 'sabía',\n",
       " 'cosas',\n",
       " 'debería',\n",
       " 'uno',\n",
       " 'pasado',\n",
       " 'después',\n",
       " 'habitación',\n",
       " 'buen',\n",
       " 'vas',\n",
       " 'deberías',\n",
       " 'escuela',\n",
       " 'casi',\n",
       " 'puerta',\n",
       " 'difícil',\n",
       " 'año',\n",
       " 'veces',\n",
       " 'niños',\n",
       " 'otro',\n",
       " 'mundo',\n",
       " 'muchos',\n",
       " 'les',\n",
       " 'amigos',\n",
       " 'allí',\n",
       " 'podría',\n",
       " 'alguna',\n",
       " 'realmente',\n",
       " 'ni',\n",
       " 'feliz',\n",
       " 'saber',\n",
       " 'hacerlo',\n",
       " 'ayuda',\n",
       " 'idea',\n",
       " 'cuánto',\n",
       " 'auto',\n",
       " 'agua',\n",
       " 'fuera',\n",
       " 'seguro',\n",
       " 'ahí',\n",
       " 'vino',\n",
       " 'mal',\n",
       " 'pronto',\n",
       " 'niño',\n",
       " 'ciudad',\n",
       " 'buena',\n",
       " 'menos',\n",
       " 'dio',\n",
       " 'visto',\n",
       " 'conmigo',\n",
       " 'comida',\n",
       " 'sabes',\n",
       " 'desde',\n",
       " 'amigo',\n",
       " 'nuestro',\n",
       " 'sólo',\n",
       " 'personas',\n",
       " 'cada',\n",
       " 'john',\n",
       " 'fiesta',\n",
       " 'tren',\n",
       " 'habla',\n",
       " 'gran',\n",
       " 'contigo',\n",
       " 'hermano',\n",
       " 'café',\n",
       " 'comprar',\n",
       " 'durante',\n",
       " 'todas',\n",
       " 'persona',\n",
       " 'haciendo',\n",
       " 'tener',\n",
       " 'nombre',\n",
       " 'dice',\n",
       " 'bueno',\n",
       " 'sea',\n",
       " 'toda',\n",
       " 'muchas',\n",
       " 'clase',\n",
       " 'lunes',\n",
       " 'vi',\n",
       " 'profesor',\n",
       " 'cama',\n",
       " 'libros',\n",
       " 'carta',\n",
       " 'acerca',\n",
       " 'tienen',\n",
       " 'pasó',\n",
       " 'policía',\n",
       " 'nuestra',\n",
       " 'japón',\n",
       " 'porque',\n",
       " 'lugar',\n",
       " 'tanto',\n",
       " 'también',\n",
       " 'leer',\n",
       " 'momento',\n",
       " 'hermana',\n",
       " 'diez',\n",
       " 'salir',\n",
       " 'rápido',\n",
       " 'padres',\n",
       " 'grande',\n",
       " 'cuenta',\n",
       " 'pudo',\n",
       " 'cerca',\n",
       " 'vive',\n",
       " 'tuvo',\n",
       " 'joven',\n",
       " 'debe',\n",
       " 'problemas',\n",
       " 'podía',\n",
       " 'vamos',\n",
       " 'siento',\n",
       " 'murió',\n",
       " 'espero',\n",
       " 'vivir',\n",
       " 'anoche',\n",
       " 'teléfono',\n",
       " 'han',\n",
       " 'gustan',\n",
       " 'aún',\n",
       " 'acuerdo',\n",
       " 'venir',\n",
       " 'historia',\n",
       " 'familia',\n",
       " 'dije',\n",
       " 'dejó',\n",
       " 'debes',\n",
       " 'sido',\n",
       " 'mujer',\n",
       " 'estaban',\n",
       " 'parte',\n",
       " 'fui',\n",
       " 'trabajar',\n",
       " 'puso',\n",
       " 'mano',\n",
       " 'cosa',\n",
       " 'nueva',\n",
       " 'horas',\n",
       " 'cinco',\n",
       " 'jugar',\n",
       " 'gracias',\n",
       " 'nadar',\n",
       " 'mesa',\n",
       " 'donde',\n",
       " 'podemos',\n",
       " 'mucha',\n",
       " 'hijo',\n",
       " 'aprender',\n",
       " 'viene',\n",
       " 'hice',\n",
       " 'estos',\n",
       " 'sí',\n",
       " 'ocupado',\n",
       " 'menudo',\n",
       " 'bastante',\n",
       " 'tomar',\n",
       " 'televisión',\n",
       " 'temprano',\n",
       " 'mayor',\n",
       " 'pregunta',\n",
       " 'pidió',\n",
       " 'última',\n",
       " 'crees',\n",
       " 'accidente',\n",
       " 'gato',\n",
       " 'dejar',\n",
       " 'camino',\n",
       " 'pasar',\n",
       " 'ayudar',\n",
       " 'suficiente',\n",
       " 'llegar',\n",
       " 'estudiar',\n",
       " 'entre',\n",
       " 'dicho',\n",
       " 'algunos',\n",
       " 'lado',\n",
       " 'encontrar',\n",
       " 'dormir',\n",
       " 'conozco',\n",
       " 'necesita',\n",
       " 'colegio',\n",
       " 'algunas',\n",
       " 'minutos',\n",
       " 'razón',\n",
       " 'mes',\n",
       " 'estación',\n",
       " 'cansado',\n",
       " 'país',\n",
       " 'mientras',\n",
       " 'algún',\n",
       " 've',\n",
       " 'importante',\n",
       " 'ventana',\n",
       " 'preguntó',\n",
       " 'película',\n",
       " 'fácil',\n",
       " 'estuvo',\n",
       " 'sola',\n",
       " 'será',\n",
       " 'tuve',\n",
       " 'vio',\n",
       " 'pienso',\n",
       " 'llegó',\n",
       " 'hijos',\n",
       " 'volver',\n",
       " 'fuerte',\n",
       " 'compró',\n",
       " 'zapatos',\n",
       " 'tipo',\n",
       " 'esperar',\n",
       " 'punto',\n",
       " 'música',\n",
       " 'hablando',\n",
       " 'frío',\n",
       " 'esperando',\n",
       " 'oficina',\n",
       " 'fueron',\n",
       " 'miedo',\n",
       " 'error',\n",
       " 'solía',\n",
       " 'pueden',\n",
       " 'importa',\n",
       " 'ganas',\n",
       " 'fin',\n",
       " 'dar',\n",
       " 'cabeza',\n",
       " 'alto',\n",
       " 'ustedes',\n",
       " 'debo',\n",
       " '¡qué',\n",
       " 'tal',\n",
       " 'lleva',\n",
       " 'buscando',\n",
       " 'cualquier',\n",
       " 'canción',\n",
       " 'primera',\n",
       " 'podrías',\n",
       " 'ido',\n",
       " 'hacia',\n",
       " 'seis',\n",
       " 'unos',\n",
       " 'queda',\n",
       " 'hemos',\n",
       " 'conducir',\n",
       " 'bicicleta',\n",
       " 'tenis',\n",
       " 'plan',\n",
       " 'contra',\n",
       " 'único',\n",
       " 'viejo',\n",
       " 'sueño',\n",
       " 'río',\n",
       " 'reunión',\n",
       " 'juntos',\n",
       " 'edad',\n",
       " 'palabra',\n",
       " 'deja',\n",
       " 'compré',\n",
       " 'ningún',\n",
       " 'reloj',\n",
       " 'ojos',\n",
       " 'quisiera',\n",
       " 'número',\n",
       " 'lejos',\n",
       " 'fumar',\n",
       " 'caja',\n",
       " 'australia',\n",
       " 'médico',\n",
       " 'misma',\n",
       " 'verte',\n",
       " 'respuesta',\n",
       " 'esposa',\n",
       " 'creer',\n",
       " 'guerra',\n",
       " 'autobús',\n",
       " 'veo',\n",
       " 'os',\n",
       " 'juego',\n",
       " 'bajo',\n",
       " 'haga',\n",
       " 'estudiantes',\n",
       " 'salió',\n",
       " 'media',\n",
       " 'estados',\n",
       " 'cree',\n",
       " 'unidos',\n",
       " 'estas',\n",
       " 'avión',\n",
       " 'verano',\n",
       " 'somos',\n",
       " 'perder',\n",
       " 'querés',\n",
       " 'pueda',\n",
       " 'pasa',\n",
       " 'iba',\n",
       " 'chico',\n",
       " 'leche',\n",
       " 'hubiera',\n",
       " 'cierto',\n",
       " 'sería',\n",
       " 'oído',\n",
       " 'dólares',\n",
       " 'usar',\n",
       " 'tienda',\n",
       " 'parecía',\n",
       " 'enfermo',\n",
       " 'chica',\n",
       " 'da',\n",
       " 'manos',\n",
       " 'hombres',\n",
       " 'regalo',\n",
       " 'quien',\n",
       " 'parque',\n",
       " 'escribir',\n",
       " 'cámara',\n",
       " 'calle',\n",
       " 'quedó',\n",
       " 'perdido',\n",
       " 'pensar',\n",
       " 'llave',\n",
       " 'libre',\n",
       " 'capaz',\n",
       " 'vos',\n",
       " 'sol',\n",
       " 'hotel',\n",
       " 'encontré',\n",
       " 'oír',\n",
       " 'listo',\n",
       " 'esté',\n",
       " 'cuántos',\n",
       " 'vaya',\n",
       " 'sos',\n",
       " 'secreto',\n",
       " 'ropa',\n",
       " 'pude',\n",
       " 'pequeño',\n",
       " 'ojalá',\n",
       " 'odio',\n",
       " 'ninguna',\n",
       " 'quieren',\n",
       " 'necesitas',\n",
       " 'hija',\n",
       " 'mío',\n",
       " 'siquiera',\n",
       " 'navidad',\n",
       " 'hagas',\n",
       " 'dolor',\n",
       " 'cuidado',\n",
       " 'terminar',\n",
       " 'estabas',\n",
       " 'cuarto',\n",
       " 'vivo',\n",
       " 'manera',\n",
       " 'interesante',\n",
       " 'hambre',\n",
       " 'deberíamos',\n",
       " 'beber',\n",
       " 'trabaja',\n",
       " 'pregunto',\n",
       " 'extraño',\n",
       " 'espera',\n",
       " 'cumpleaños',\n",
       " 'acá',\n",
       " 'queremos',\n",
       " 'perdió',\n",
       " 'hiciste',\n",
       " 'flores',\n",
       " 'suerte',\n",
       " 'rico',\n",
       " 'próximo',\n",
       " 'preguntas',\n",
       " 'muerte',\n",
       " 'hospital',\n",
       " 'vuelta',\n",
       " 'vacaciones',\n",
       " 'luz',\n",
       " 'entender',\n",
       " 'duro',\n",
       " 'cara',\n",
       " 'allá',\n",
       " 'ven',\n",
       " 'tokio',\n",
       " 'posible',\n",
       " 'malo',\n",
       " 'déjame',\n",
       " 'cuatro',\n",
       " 'consejo',\n",
       " 'calor',\n",
       " 'volvió',\n",
       " 'té',\n",
       " 'primero',\n",
       " 'pelo',\n",
       " 'palabras',\n",
       " 'haré',\n",
       " 'empezó',\n",
       " 'árbol',\n",
       " 'van',\n",
       " 'tomó',\n",
       " 'terminado',\n",
       " 'novia',\n",
       " 'necesitamos',\n",
       " 'haya',\n",
       " 'falta',\n",
       " 'entiendo',\n",
       " 'doctor',\n",
       " 'cuanto',\n",
       " 'cocina',\n",
       " 'bebé',\n",
       " 'tarea',\n",
       " 'justo',\n",
       " 'jamás',\n",
       " 'tío',\n",
       " 'tocar',\n",
       " 'realidad',\n",
       " 'encanta',\n",
       " 'conoce',\n",
       " 'unas',\n",
       " 'ruido',\n",
       " 'perros',\n",
       " 'nieve',\n",
       " 'largo',\n",
       " 'estudiante',\n",
       " 'entrar',\n",
       " 'di',\n",
       " 'culpa',\n",
       " 'canadiense',\n",
       " 'recuerdo',\n",
       " 'quieras',\n",
       " 'oportunidad',\n",
       " 'niña',\n",
       " 'estaré',\n",
       " 'primer',\n",
       " 'equipo',\n",
       " 'viaje',\n",
       " 'lista',\n",
       " 'japonés',\n",
       " 'forma',\n",
       " 'examen',\n",
       " 'entonces',\n",
       " 'decisión',\n",
       " 'compañía',\n",
       " 'cerveza',\n",
       " 'cantar',\n",
       " 'banco',\n",
       " 'asunto',\n",
       " 'vista',\n",
       " 'tenido',\n",
       " 'otros',\n",
       " 'lengua',\n",
       " 'esperaba',\n",
       " 'dentro',\n",
       " 'trabajando',\n",
       " 'piensa',\n",
       " 'pequeña',\n",
       " 'pensando',\n",
       " 'fútbol',\n",
       " 'eran',\n",
       " 'equivocado',\n",
       " 'diccionario',\n",
       " 'cena',\n",
       " 'acaso',\n",
       " 'piano',\n",
       " 'loco',\n",
       " 'extranjero',\n",
       " 'decidió',\n",
       " 'debemos',\n",
       " 'béisbol',\n",
       " 'apenas',\n",
       " 'llover',\n",
       " 'jardín',\n",
       " 'exactamente',\n",
       " 'errores',\n",
       " 'aquel',\n",
       " 'visitar',\n",
       " 'vestido',\n",
       " 'puesto',\n",
       " 'piensas',\n",
       " 'pie',\n",
       " 'perdí',\n",
       " 'fuego',\n",
       " 'encontró',\n",
       " 'edificio',\n",
       " 'clases',\n",
       " 'alrededor',\n",
       " 'éxito',\n",
       " 'universidad',\n",
       " 'peor',\n",
       " 'par',\n",
       " 'mujeres',\n",
       " 'llama',\n",
       " 'haría',\n",
       " 'foto',\n",
       " 'estuve',\n",
       " 'esos',\n",
       " 'carne',\n",
       " 'camisa',\n",
       " 'caminar',\n",
       " 'amor',\n",
       " 'venga',\n",
       " 'salud',\n",
       " 'restaurante',\n",
       " 'prefiero',\n",
       " 'pensaba',\n",
       " 'gatos',\n",
       " 'estudiando',\n",
       " 'dame',\n",
       " 'cayó',\n",
       " 'frente',\n",
       " 'china',\n",
       " 'animales',\n",
       " 'vendrá',\n",
       " 'mala',\n",
       " 'leyendo',\n",
       " 'favorito',\n",
       " 'dormido',\n",
       " 'cenar',\n",
       " 'biblioteca',\n",
       " 'baño',\n",
       " '¡no',\n",
       " 'pasando',\n",
       " 'montón',\n",
       " 'llorar',\n",
       " 'concierto',\n",
       " 'única',\n",
       " 'treinta',\n",
       " 'sombrero',\n",
       " 'poder',\n",
       " 'pedí',\n",
       " 'nuestros',\n",
       " 'guitarra',\n",
       " 'escuchar',\n",
       " 'ves',\n",
       " 'muerto',\n",
       " 'estará',\n",
       " 'ellas',\n",
       " 'comió',\n",
       " 'come',\n",
       " 'bus',\n",
       " 'atención',\n",
       " 'acabo',\n",
       " 'abogado',\n",
       " 'taza',\n",
       " 'siete',\n",
       " 'pareces',\n",
       " 'mía',\n",
       " 'mira',\n",
       " 'lluvia',\n",
       " 'inteligente',\n",
       " 'estúpido',\n",
       " 'conseguir',\n",
       " 'completamente',\n",
       " 'rompió',\n",
       " 'radio',\n",
       " 'cuántas',\n",
       " 'caso',\n",
       " 'acaba',\n",
       " 'abuelo',\n",
       " 'vaso',\n",
       " 'sitio',\n",
       " 'sigue',\n",
       " 'peso',\n",
       " 'peligro',\n",
       " 'habría',\n",
       " 'papá',\n",
       " 'ocurrió',\n",
       " 'llamar',\n",
       " 'dirección',\n",
       " 'cuesta',\n",
       " 'cuchillo',\n",
       " 'aconsejó',\n",
       " 'tenés',\n",
       " 'situación',\n",
       " 'pagar',\n",
       " 'opinión',\n",
       " 'llevar',\n",
       " 'invierno',\n",
       " 'ganar',\n",
       " 'esas',\n",
       " 'entró',\n",
       " 'ello',\n",
       " 'digas',\n",
       " 'deberes',\n",
       " 'cine',\n",
       " 'blanco',\n",
       " 'barco',\n",
       " 'almuerzo',\n",
       " 'londres',\n",
       " 'jugando',\n",
       " 'causa',\n",
       " 'casado',\n",
       " 'vale',\n",
       " 'rato',\n",
       " 'oí',\n",
       " 'montaña',\n",
       " 'estáis',\n",
       " 'dijiste',\n",
       " 'decirle',\n",
       " 'comido',\n",
       " 'ayudarte',\n",
       " 'atrás',\n",
       " 'aire',\n",
       " 'saben',\n",
       " 'medio',\n",
       " 'finalmente',\n",
       " 'final',\n",
       " 'carro',\n",
       " 'viven',\n",
       " 'toma',\n",
       " 'suficientemente',\n",
       " 'siendo',\n",
       " 'sentido',\n",
       " 'pieza',\n",
       " 'ocupada',\n",
       " 'ocho',\n",
       " 'miró',\n",
       " 'meses',\n",
       " 'chicos',\n",
       " 'último',\n",
       " 'siguió',\n",
       " 'sentó',\n",
       " 'llevaba',\n",
       " 'dime',\n",
       " 'terminó',\n",
       " 'playa',\n",
       " 'partido',\n",
       " 'paraguas',\n",
       " 'morir',\n",
       " 'llegué',\n",
       " 'llamó',\n",
       " 'jefe',\n",
       " 'huevos',\n",
       " 'hubo',\n",
       " 'grandes',\n",
       " 'desearía',\n",
       " 'sal',\n",
       " 'responder',\n",
       " 'respecto',\n",
       " 'pan',\n",
       " 'imposible',\n",
       " 'corriendo',\n",
       " 'aeropuerto',\n",
       " 'silla',\n",
       " 'pasada',\n",
       " 'mamá',\n",
       " 'irme',\n",
       " 'intentando',\n",
       " 'haz',\n",
       " 'duele',\n",
       " 'diga',\n",
       " 'corazón',\n",
       " 'confiar',\n",
       " 'clima',\n",
       " 'cambiar',\n",
       " 'voz',\n",
       " 'trató',\n",
       " 'sala',\n",
       " 'quedarme',\n",
       " 'pescado',\n",
       " 'peligroso',\n",
       " 'paciente',\n",
       " 'manzana',\n",
       " 'funciona',\n",
       " 'divertido',\n",
       " 'viste',\n",
       " 'triste',\n",
       " 'semanas',\n",
       " 'reglas',\n",
       " 'probablemente',\n",
       " 'pena',\n",
       " 'papel',\n",
       " 'normalmente',\n",
       " 'manzanas',\n",
       " 'hermosa',\n",
       " 'escritorio',\n",
       " 'dile',\n",
       " 'correcto',\n",
       " 'conoces',\n",
       " 'venido',\n",
       " 'trata',\n",
       " 'torta',\n",
       " 'minuto',\n",
       " 'irse',\n",
       " 'intentó',\n",
       " 'hablo',\n",
       " 'derecho',\n",
       " 'ayudó',\n",
       " 'afuera',\n",
       " 'simplemente',\n",
       " 'sale',\n",
       " 'lleno',\n",
       " 'lamento',\n",
       " 'hiciera',\n",
       " 'hermanos',\n",
       " 'haces',\n",
       " 'estés',\n",
       " 'dicen',\n",
       " 'comiendo',\n",
       " 'ambos',\n",
       " 'viendo',\n",
       " 'vayas',\n",
       " 'taxi',\n",
       " 'supongo',\n",
       " 'rojo',\n",
       " 'pueblo',\n",
       " 'poner',\n",
       " 'ninguno',\n",
       " 'nació',\n",
       " 'mayoría',\n",
       " 'iglesia',\n",
       " 'fotos',\n",
       " 'dejes',\n",
       " 'alta',\n",
       " 'tierra',\n",
       " 'significa',\n",
       " 'seguir',\n",
       " 'quiera',\n",
       " 'quedarse',\n",
       " 'parís',\n",
       " 'mirando',\n",
       " 'llaves',\n",
       " 'lago',\n",
       " 'favorita',\n",
       " 'cocinar',\n",
       " 'cielo',\n",
       " 'viajar',\n",
       " 'verme',\n",
       " 'suelo',\n",
       " 'resolver',\n",
       " 'próxima',\n",
       " 'piso',\n",
       " 'novio',\n",
       " 'mensaje',\n",
       " 'mar',\n",
       " 'estaría',\n",
       " 'empezar',\n",
       " 'domingo',\n",
       " 'boca',\n",
       " 'amo',\n",
       " 'traje',\n",
       " 'serio',\n",
       " 'sacó',\n",
       " 'quedé',\n",
       " 'pensó',\n",
       " 'noticias',\n",
       " 'negro',\n",
       " 'necesario',\n",
       " 'habló',\n",
       " 'escribió',\n",
       " 'diciendo',\n",
       " 'desayuno',\n",
       " 'contento',\n",
       " 'comprado',\n",
       " 'buenas',\n",
       " 'abierta',\n",
       " 'varias',\n",
       " 'podés',\n",
       " 'olvidó',\n",
       " 'necesitaba',\n",
       " 'iré',\n",
       " 'incluso',\n",
       " 'futuro',\n",
       " 'francia',\n",
       " 'empleo',\n",
       " 'domingos',\n",
       " 'demás',\n",
       " 'decirme',\n",
       " 'caliente',\n",
       " 'caballo',\n",
       " 'ayudarme',\n",
       " 'prisa',\n",
       " 'gustaba',\n",
       " 'fuimos',\n",
       " 'felices',\n",
       " 'dios',\n",
       " 'contó',\n",
       " 'cita',\n",
       " 'buenos',\n",
       " 'brazo',\n",
       " 'anciano',\n",
       " 'amable',\n",
       " 'abrió',\n",
       " 'abrigo',\n",
       " 'york',\n",
       " 'pobre',\n",
       " 'periódico',\n",
       " 'pase',\n",
       " 'llegado',\n",
       " 'entiende',\n",
       " 'comenzó',\n",
       " 'bailar',\n",
       " 'vosotros',\n",
       " 'presidente',\n",
       " 'pared',\n",
       " 'mil',\n",
       " 'matar',\n",
       " 'hicieron',\n",
       " 'helado',\n",
       " 'daño',\n",
       " 'cartas',\n",
       " 'ama',\n",
       " 'abrir',\n",
       " 'vuelve',\n",
       " 'tratando',\n",
       " 'siguiente',\n",
       " 'siente',\n",
       " 'prueba',\n",
       " 'llevó',\n",
       " 'leído',\n",
       " 'estábamos',\n",
       " 'escrito',\n",
       " 'diferente',\n",
       " 'dejé',\n",
       " 'casó',\n",
       " 'aunque',\n",
       " 'aquella',\n",
       " 'amiga',\n",
       " 'adónde',\n",
       " 'tarta',\n",
       " 'preocupado',\n",
       " 'noticia',\n",
       " 'mantener',\n",
       " 'llegue',\n",
       " 'lentes',\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_vocab = target_vectorizer.get_vocabulary()\n",
    "target_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dd88f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '',\n",
       " 1: '[UNK]',\n",
       " 2: '[start]',\n",
       " 3: '[end]',\n",
       " 4: 'de',\n",
       " 5: 'que',\n",
       " 6: 'a',\n",
       " 7: 'no',\n",
       " 8: 'tom',\n",
       " 9: 'la',\n",
       " 10: 'el',\n",
       " 11: 'en',\n",
       " 12: 'es',\n",
       " 13: 'un',\n",
       " 14: 'me',\n",
       " 15: 'se',\n",
       " 16: 'por',\n",
       " 17: 'lo',\n",
       " 18: 'una',\n",
       " 19: 'Él',\n",
       " 20: 'su',\n",
       " 21: 'está',\n",
       " 22: 'los',\n",
       " 23: 'mi',\n",
       " 24: 'con',\n",
       " 25: 'le',\n",
       " 26: 'ella',\n",
       " 27: 'qué',\n",
       " 28: 'te',\n",
       " 29: 'para',\n",
       " 30: 'mary',\n",
       " 31: 'las',\n",
       " 32: 'y',\n",
       " 33: 'más',\n",
       " 34: 'al',\n",
       " 35: 'yo',\n",
       " 36: 'tu',\n",
       " 37: 'estoy',\n",
       " 38: 'muy',\n",
       " 39: 'eso',\n",
       " 40: 'tiene',\n",
       " 41: 'esta',\n",
       " 42: 'este',\n",
       " 43: 'del',\n",
       " 44: 'quiero',\n",
       " 45: 'él',\n",
       " 46: 'estaba',\n",
       " 47: 'tengo',\n",
       " 48: 'fue',\n",
       " 49: 'si',\n",
       " 50: 'aquí',\n",
       " 51: 'casa',\n",
       " 52: 'hacer',\n",
       " 53: 'como',\n",
       " 54: 'puedo',\n",
       " 55: 'esto',\n",
       " 56: 'algo',\n",
       " 57: 'todo',\n",
       " 58: 'hay',\n",
       " 59: 'tiempo',\n",
       " 60: 'ha',\n",
       " 61: 'gusta',\n",
       " 62: 'tan',\n",
       " 63: 'son',\n",
       " 64: 'todos',\n",
       " 65: 'favor',\n",
       " 66: 'ir',\n",
       " 67: 'nada',\n",
       " 68: 'puede',\n",
       " 69: 'era',\n",
       " 70: 'vez',\n",
       " 71: 'bien',\n",
       " 72: 'cuando',\n",
       " 73: 'he',\n",
       " 74: 'mucho',\n",
       " 75: 'solo',\n",
       " 76: 'ellos',\n",
       " 77: 'sé',\n",
       " 78: 'nos',\n",
       " 79: 'mañana',\n",
       " 80: 'nunca',\n",
       " 81: 'dos',\n",
       " 82: 'ser',\n",
       " 83: 'creo',\n",
       " 84: 'ya',\n",
       " 85: 'dónde',\n",
       " 86: 'sus',\n",
       " 87: 'dinero',\n",
       " 88: 'trabajo',\n",
       " 89: 'cómo',\n",
       " 90: 'dijo',\n",
       " 91: 'ahora',\n",
       " 92: 'estás',\n",
       " 93: 'quién',\n",
       " 94: 'hablar',\n",
       " 95: 'tienes',\n",
       " 96: 'pero',\n",
       " 97: 'tomás',\n",
       " 98: 'están',\n",
       " 99: 'siempre',\n",
       " 100: 'ese',\n",
       " 101: 'soy',\n",
       " 102: 'día',\n",
       " 103: 'tú',\n",
       " 104: 'puedes',\n",
       " 105: 'voy',\n",
       " 106: 'libro',\n",
       " 107: 'había',\n",
       " 108: 'hace',\n",
       " 109: 'hoy',\n",
       " 110: 'verdad',\n",
       " 111: 'nadie',\n",
       " 112: 'poco',\n",
       " 113: 'quiere',\n",
       " 114: 'esa',\n",
       " 115: 'sabe',\n",
       " 116: 'estar',\n",
       " 117: 'ver',\n",
       " 118: 'va',\n",
       " 119: 'mejor',\n",
       " 120: 'años',\n",
       " 121: 'has',\n",
       " 122: 'demasiado',\n",
       " 123: 'quieres',\n",
       " 124: 'padre',\n",
       " 125: 'francés',\n",
       " 126: 'antes',\n",
       " 127: 'tarde',\n",
       " 128: 'eres',\n",
       " 129: 'mis',\n",
       " 130: 'quería',\n",
       " 131: 'maría',\n",
       " 132: 'hizo',\n",
       " 133: 'tenía',\n",
       " 134: 'usted',\n",
       " 135: 'parece',\n",
       " 136: 'tres',\n",
       " 137: 'hora',\n",
       " 138: 'noche',\n",
       " 139: 'boston',\n",
       " 140: 'o',\n",
       " 141: 'sobre',\n",
       " 142: 'sin',\n",
       " 143: 'haber',\n",
       " 144: 'ayer',\n",
       " 145: 'hasta',\n",
       " 146: 'perro',\n",
       " 147: 'mí',\n",
       " 148: 'hombre',\n",
       " 149: 'necesito',\n",
       " 150: 'alguien',\n",
       " 151: 'vida',\n",
       " 152: 'inglés',\n",
       " 153: 'todavía',\n",
       " 154: 'estado',\n",
       " 155: 'cuál',\n",
       " 156: 'comer',\n",
       " 157: 'cuándo',\n",
       " 158: 'nuevo',\n",
       " 159: 'hecho',\n",
       " 160: 'días',\n",
       " 161: 'tenemos',\n",
       " 162: 'madre',\n",
       " 163: 'coche',\n",
       " 164: 'mismo',\n",
       " 165: 'decir',\n",
       " 166: 'nosotros',\n",
       " 167: 'así',\n",
       " 168: 'problema',\n",
       " 169: 'gustaría',\n",
       " 170: 'gente',\n",
       " 171: 'pensé',\n",
       " 172: 'otra',\n",
       " 173: 'semana',\n",
       " 174: 'tus',\n",
       " 175: 'estamos',\n",
       " 176: 'ti',\n",
       " 177: 'sabía',\n",
       " 178: 'cosas',\n",
       " 179: 'debería',\n",
       " 180: 'uno',\n",
       " 181: 'pasado',\n",
       " 182: 'después',\n",
       " 183: 'habitación',\n",
       " 184: 'buen',\n",
       " 185: 'vas',\n",
       " 186: 'deberías',\n",
       " 187: 'escuela',\n",
       " 188: 'casi',\n",
       " 189: 'puerta',\n",
       " 190: 'difícil',\n",
       " 191: 'año',\n",
       " 192: 'veces',\n",
       " 193: 'niños',\n",
       " 194: 'otro',\n",
       " 195: 'mundo',\n",
       " 196: 'muchos',\n",
       " 197: 'les',\n",
       " 198: 'amigos',\n",
       " 199: 'allí',\n",
       " 200: 'podría',\n",
       " 201: 'alguna',\n",
       " 202: 'realmente',\n",
       " 203: 'ni',\n",
       " 204: 'feliz',\n",
       " 205: 'saber',\n",
       " 206: 'hacerlo',\n",
       " 207: 'ayuda',\n",
       " 208: 'idea',\n",
       " 209: 'cuánto',\n",
       " 210: 'auto',\n",
       " 211: 'agua',\n",
       " 212: 'fuera',\n",
       " 213: 'seguro',\n",
       " 214: 'ahí',\n",
       " 215: 'vino',\n",
       " 216: 'mal',\n",
       " 217: 'pronto',\n",
       " 218: 'niño',\n",
       " 219: 'ciudad',\n",
       " 220: 'buena',\n",
       " 221: 'menos',\n",
       " 222: 'dio',\n",
       " 223: 'visto',\n",
       " 224: 'conmigo',\n",
       " 225: 'comida',\n",
       " 226: 'sabes',\n",
       " 227: 'desde',\n",
       " 228: 'amigo',\n",
       " 229: 'nuestro',\n",
       " 230: 'sólo',\n",
       " 231: 'personas',\n",
       " 232: 'cada',\n",
       " 233: 'john',\n",
       " 234: 'fiesta',\n",
       " 235: 'tren',\n",
       " 236: 'habla',\n",
       " 237: 'gran',\n",
       " 238: 'contigo',\n",
       " 239: 'hermano',\n",
       " 240: 'café',\n",
       " 241: 'comprar',\n",
       " 242: 'durante',\n",
       " 243: 'todas',\n",
       " 244: 'persona',\n",
       " 245: 'haciendo',\n",
       " 246: 'tener',\n",
       " 247: 'nombre',\n",
       " 248: 'dice',\n",
       " 249: 'bueno',\n",
       " 250: 'sea',\n",
       " 251: 'toda',\n",
       " 252: 'muchas',\n",
       " 253: 'clase',\n",
       " 254: 'lunes',\n",
       " 255: 'vi',\n",
       " 256: 'profesor',\n",
       " 257: 'cama',\n",
       " 258: 'libros',\n",
       " 259: 'carta',\n",
       " 260: 'acerca',\n",
       " 261: 'tienen',\n",
       " 262: 'pasó',\n",
       " 263: 'policía',\n",
       " 264: 'nuestra',\n",
       " 265: 'japón',\n",
       " 266: 'porque',\n",
       " 267: 'lugar',\n",
       " 268: 'tanto',\n",
       " 269: 'también',\n",
       " 270: 'leer',\n",
       " 271: 'momento',\n",
       " 272: 'hermana',\n",
       " 273: 'diez',\n",
       " 274: 'salir',\n",
       " 275: 'rápido',\n",
       " 276: 'padres',\n",
       " 277: 'grande',\n",
       " 278: 'cuenta',\n",
       " 279: 'pudo',\n",
       " 280: 'cerca',\n",
       " 281: 'vive',\n",
       " 282: 'tuvo',\n",
       " 283: 'joven',\n",
       " 284: 'debe',\n",
       " 285: 'problemas',\n",
       " 286: 'podía',\n",
       " 287: 'vamos',\n",
       " 288: 'siento',\n",
       " 289: 'murió',\n",
       " 290: 'espero',\n",
       " 291: 'vivir',\n",
       " 292: 'anoche',\n",
       " 293: 'teléfono',\n",
       " 294: 'han',\n",
       " 295: 'gustan',\n",
       " 296: 'aún',\n",
       " 297: 'acuerdo',\n",
       " 298: 'venir',\n",
       " 299: 'historia',\n",
       " 300: 'familia',\n",
       " 301: 'dije',\n",
       " 302: 'dejó',\n",
       " 303: 'debes',\n",
       " 304: 'sido',\n",
       " 305: 'mujer',\n",
       " 306: 'estaban',\n",
       " 307: 'parte',\n",
       " 308: 'fui',\n",
       " 309: 'trabajar',\n",
       " 310: 'puso',\n",
       " 311: 'mano',\n",
       " 312: 'cosa',\n",
       " 313: 'nueva',\n",
       " 314: 'horas',\n",
       " 315: 'cinco',\n",
       " 316: 'jugar',\n",
       " 317: 'gracias',\n",
       " 318: 'nadar',\n",
       " 319: 'mesa',\n",
       " 320: 'donde',\n",
       " 321: 'podemos',\n",
       " 322: 'mucha',\n",
       " 323: 'hijo',\n",
       " 324: 'aprender',\n",
       " 325: 'viene',\n",
       " 326: 'hice',\n",
       " 327: 'estos',\n",
       " 328: 'sí',\n",
       " 329: 'ocupado',\n",
       " 330: 'menudo',\n",
       " 331: 'bastante',\n",
       " 332: 'tomar',\n",
       " 333: 'televisión',\n",
       " 334: 'temprano',\n",
       " 335: 'mayor',\n",
       " 336: 'pregunta',\n",
       " 337: 'pidió',\n",
       " 338: 'última',\n",
       " 339: 'crees',\n",
       " 340: 'accidente',\n",
       " 341: 'gato',\n",
       " 342: 'dejar',\n",
       " 343: 'camino',\n",
       " 344: 'pasar',\n",
       " 345: 'ayudar',\n",
       " 346: 'suficiente',\n",
       " 347: 'llegar',\n",
       " 348: 'estudiar',\n",
       " 349: 'entre',\n",
       " 350: 'dicho',\n",
       " 351: 'algunos',\n",
       " 352: 'lado',\n",
       " 353: 'encontrar',\n",
       " 354: 'dormir',\n",
       " 355: 'conozco',\n",
       " 356: 'necesita',\n",
       " 357: 'colegio',\n",
       " 358: 'algunas',\n",
       " 359: 'minutos',\n",
       " 360: 'razón',\n",
       " 361: 'mes',\n",
       " 362: 'estación',\n",
       " 363: 'cansado',\n",
       " 364: 'país',\n",
       " 365: 'mientras',\n",
       " 366: 'algún',\n",
       " 367: 've',\n",
       " 368: 'importante',\n",
       " 369: 'ventana',\n",
       " 370: 'preguntó',\n",
       " 371: 'película',\n",
       " 372: 'fácil',\n",
       " 373: 'estuvo',\n",
       " 374: 'sola',\n",
       " 375: 'será',\n",
       " 376: 'tuve',\n",
       " 377: 'vio',\n",
       " 378: 'pienso',\n",
       " 379: 'llegó',\n",
       " 380: 'hijos',\n",
       " 381: 'volver',\n",
       " 382: 'fuerte',\n",
       " 383: 'compró',\n",
       " 384: 'zapatos',\n",
       " 385: 'tipo',\n",
       " 386: 'esperar',\n",
       " 387: 'punto',\n",
       " 388: 'música',\n",
       " 389: 'hablando',\n",
       " 390: 'frío',\n",
       " 391: 'esperando',\n",
       " 392: 'oficina',\n",
       " 393: 'fueron',\n",
       " 394: 'miedo',\n",
       " 395: 'error',\n",
       " 396: 'solía',\n",
       " 397: 'pueden',\n",
       " 398: 'importa',\n",
       " 399: 'ganas',\n",
       " 400: 'fin',\n",
       " 401: 'dar',\n",
       " 402: 'cabeza',\n",
       " 403: 'alto',\n",
       " 404: 'ustedes',\n",
       " 405: 'debo',\n",
       " 406: '¡qué',\n",
       " 407: 'tal',\n",
       " 408: 'lleva',\n",
       " 409: 'buscando',\n",
       " 410: 'cualquier',\n",
       " 411: 'canción',\n",
       " 412: 'primera',\n",
       " 413: 'podrías',\n",
       " 414: 'ido',\n",
       " 415: 'hacia',\n",
       " 416: 'seis',\n",
       " 417: 'unos',\n",
       " 418: 'queda',\n",
       " 419: 'hemos',\n",
       " 420: 'conducir',\n",
       " 421: 'bicicleta',\n",
       " 422: 'tenis',\n",
       " 423: 'plan',\n",
       " 424: 'contra',\n",
       " 425: 'único',\n",
       " 426: 'viejo',\n",
       " 427: 'sueño',\n",
       " 428: 'río',\n",
       " 429: 'reunión',\n",
       " 430: 'juntos',\n",
       " 431: 'edad',\n",
       " 432: 'palabra',\n",
       " 433: 'deja',\n",
       " 434: 'compré',\n",
       " 435: 'ningún',\n",
       " 436: 'reloj',\n",
       " 437: 'ojos',\n",
       " 438: 'quisiera',\n",
       " 439: 'número',\n",
       " 440: 'lejos',\n",
       " 441: 'fumar',\n",
       " 442: 'caja',\n",
       " 443: 'australia',\n",
       " 444: 'médico',\n",
       " 445: 'misma',\n",
       " 446: 'verte',\n",
       " 447: 'respuesta',\n",
       " 448: 'esposa',\n",
       " 449: 'creer',\n",
       " 450: 'guerra',\n",
       " 451: 'autobús',\n",
       " 452: 'veo',\n",
       " 453: 'os',\n",
       " 454: 'juego',\n",
       " 455: 'bajo',\n",
       " 456: 'haga',\n",
       " 457: 'estudiantes',\n",
       " 458: 'salió',\n",
       " 459: 'media',\n",
       " 460: 'estados',\n",
       " 461: 'cree',\n",
       " 462: 'unidos',\n",
       " 463: 'estas',\n",
       " 464: 'avión',\n",
       " 465: 'verano',\n",
       " 466: 'somos',\n",
       " 467: 'perder',\n",
       " 468: 'querés',\n",
       " 469: 'pueda',\n",
       " 470: 'pasa',\n",
       " 471: 'iba',\n",
       " 472: 'chico',\n",
       " 473: 'leche',\n",
       " 474: 'hubiera',\n",
       " 475: 'cierto',\n",
       " 476: 'sería',\n",
       " 477: 'oído',\n",
       " 478: 'dólares',\n",
       " 479: 'usar',\n",
       " 480: 'tienda',\n",
       " 481: 'parecía',\n",
       " 482: 'enfermo',\n",
       " 483: 'chica',\n",
       " 484: 'da',\n",
       " 485: 'manos',\n",
       " 486: 'hombres',\n",
       " 487: 'regalo',\n",
       " 488: 'quien',\n",
       " 489: 'parque',\n",
       " 490: 'escribir',\n",
       " 491: 'cámara',\n",
       " 492: 'calle',\n",
       " 493: 'quedó',\n",
       " 494: 'perdido',\n",
       " 495: 'pensar',\n",
       " 496: 'llave',\n",
       " 497: 'libre',\n",
       " 498: 'capaz',\n",
       " 499: 'vos',\n",
       " 500: 'sol',\n",
       " 501: 'hotel',\n",
       " 502: 'encontré',\n",
       " 503: 'oír',\n",
       " 504: 'listo',\n",
       " 505: 'esté',\n",
       " 506: 'cuántos',\n",
       " 507: 'vaya',\n",
       " 508: 'sos',\n",
       " 509: 'secreto',\n",
       " 510: 'ropa',\n",
       " 511: 'pude',\n",
       " 512: 'pequeño',\n",
       " 513: 'ojalá',\n",
       " 514: 'odio',\n",
       " 515: 'ninguna',\n",
       " 516: 'quieren',\n",
       " 517: 'necesitas',\n",
       " 518: 'hija',\n",
       " 519: 'mío',\n",
       " 520: 'siquiera',\n",
       " 521: 'navidad',\n",
       " 522: 'hagas',\n",
       " 523: 'dolor',\n",
       " 524: 'cuidado',\n",
       " 525: 'terminar',\n",
       " 526: 'estabas',\n",
       " 527: 'cuarto',\n",
       " 528: 'vivo',\n",
       " 529: 'manera',\n",
       " 530: 'interesante',\n",
       " 531: 'hambre',\n",
       " 532: 'deberíamos',\n",
       " 533: 'beber',\n",
       " 534: 'trabaja',\n",
       " 535: 'pregunto',\n",
       " 536: 'extraño',\n",
       " 537: 'espera',\n",
       " 538: 'cumpleaños',\n",
       " 539: 'acá',\n",
       " 540: 'queremos',\n",
       " 541: 'perdió',\n",
       " 542: 'hiciste',\n",
       " 543: 'flores',\n",
       " 544: 'suerte',\n",
       " 545: 'rico',\n",
       " 546: 'próximo',\n",
       " 547: 'preguntas',\n",
       " 548: 'muerte',\n",
       " 549: 'hospital',\n",
       " 550: 'vuelta',\n",
       " 551: 'vacaciones',\n",
       " 552: 'luz',\n",
       " 553: 'entender',\n",
       " 554: 'duro',\n",
       " 555: 'cara',\n",
       " 556: 'allá',\n",
       " 557: 'ven',\n",
       " 558: 'tokio',\n",
       " 559: 'posible',\n",
       " 560: 'malo',\n",
       " 561: 'déjame',\n",
       " 562: 'cuatro',\n",
       " 563: 'consejo',\n",
       " 564: 'calor',\n",
       " 565: 'volvió',\n",
       " 566: 'té',\n",
       " 567: 'primero',\n",
       " 568: 'pelo',\n",
       " 569: 'palabras',\n",
       " 570: 'haré',\n",
       " 571: 'empezó',\n",
       " 572: 'árbol',\n",
       " 573: 'van',\n",
       " 574: 'tomó',\n",
       " 575: 'terminado',\n",
       " 576: 'novia',\n",
       " 577: 'necesitamos',\n",
       " 578: 'haya',\n",
       " 579: 'falta',\n",
       " 580: 'entiendo',\n",
       " 581: 'doctor',\n",
       " 582: 'cuanto',\n",
       " 583: 'cocina',\n",
       " 584: 'bebé',\n",
       " 585: 'tarea',\n",
       " 586: 'justo',\n",
       " 587: 'jamás',\n",
       " 588: 'tío',\n",
       " 589: 'tocar',\n",
       " 590: 'realidad',\n",
       " 591: 'encanta',\n",
       " 592: 'conoce',\n",
       " 593: 'unas',\n",
       " 594: 'ruido',\n",
       " 595: 'perros',\n",
       " 596: 'nieve',\n",
       " 597: 'largo',\n",
       " 598: 'estudiante',\n",
       " 599: 'entrar',\n",
       " 600: 'di',\n",
       " 601: 'culpa',\n",
       " 602: 'canadiense',\n",
       " 603: 'recuerdo',\n",
       " 604: 'quieras',\n",
       " 605: 'oportunidad',\n",
       " 606: 'niña',\n",
       " 607: 'estaré',\n",
       " 608: 'primer',\n",
       " 609: 'equipo',\n",
       " 610: 'viaje',\n",
       " 611: 'lista',\n",
       " 612: 'japonés',\n",
       " 613: 'forma',\n",
       " 614: 'examen',\n",
       " 615: 'entonces',\n",
       " 616: 'decisión',\n",
       " 617: 'compañía',\n",
       " 618: 'cerveza',\n",
       " 619: 'cantar',\n",
       " 620: 'banco',\n",
       " 621: 'asunto',\n",
       " 622: 'vista',\n",
       " 623: 'tenido',\n",
       " 624: 'otros',\n",
       " 625: 'lengua',\n",
       " 626: 'esperaba',\n",
       " 627: 'dentro',\n",
       " 628: 'trabajando',\n",
       " 629: 'piensa',\n",
       " 630: 'pequeña',\n",
       " 631: 'pensando',\n",
       " 632: 'fútbol',\n",
       " 633: 'eran',\n",
       " 634: 'equivocado',\n",
       " 635: 'diccionario',\n",
       " 636: 'cena',\n",
       " 637: 'acaso',\n",
       " 638: 'piano',\n",
       " 639: 'loco',\n",
       " 640: 'extranjero',\n",
       " 641: 'decidió',\n",
       " 642: 'debemos',\n",
       " 643: 'béisbol',\n",
       " 644: 'apenas',\n",
       " 645: 'llover',\n",
       " 646: 'jardín',\n",
       " 647: 'exactamente',\n",
       " 648: 'errores',\n",
       " 649: 'aquel',\n",
       " 650: 'visitar',\n",
       " 651: 'vestido',\n",
       " 652: 'puesto',\n",
       " 653: 'piensas',\n",
       " 654: 'pie',\n",
       " 655: 'perdí',\n",
       " 656: 'fuego',\n",
       " 657: 'encontró',\n",
       " 658: 'edificio',\n",
       " 659: 'clases',\n",
       " 660: 'alrededor',\n",
       " 661: 'éxito',\n",
       " 662: 'universidad',\n",
       " 663: 'peor',\n",
       " 664: 'par',\n",
       " 665: 'mujeres',\n",
       " 666: 'llama',\n",
       " 667: 'haría',\n",
       " 668: 'foto',\n",
       " 669: 'estuve',\n",
       " 670: 'esos',\n",
       " 671: 'carne',\n",
       " 672: 'camisa',\n",
       " 673: 'caminar',\n",
       " 674: 'amor',\n",
       " 675: 'venga',\n",
       " 676: 'salud',\n",
       " 677: 'restaurante',\n",
       " 678: 'prefiero',\n",
       " 679: 'pensaba',\n",
       " 680: 'gatos',\n",
       " 681: 'estudiando',\n",
       " 682: 'dame',\n",
       " 683: 'cayó',\n",
       " 684: 'frente',\n",
       " 685: 'china',\n",
       " 686: 'animales',\n",
       " 687: 'vendrá',\n",
       " 688: 'mala',\n",
       " 689: 'leyendo',\n",
       " 690: 'favorito',\n",
       " 691: 'dormido',\n",
       " 692: 'cenar',\n",
       " 693: 'biblioteca',\n",
       " 694: 'baño',\n",
       " 695: '¡no',\n",
       " 696: 'pasando',\n",
       " 697: 'montón',\n",
       " 698: 'llorar',\n",
       " 699: 'concierto',\n",
       " 700: 'única',\n",
       " 701: 'treinta',\n",
       " 702: 'sombrero',\n",
       " 703: 'poder',\n",
       " 704: 'pedí',\n",
       " 705: 'nuestros',\n",
       " 706: 'guitarra',\n",
       " 707: 'escuchar',\n",
       " 708: 'ves',\n",
       " 709: 'muerto',\n",
       " 710: 'estará',\n",
       " 711: 'ellas',\n",
       " 712: 'comió',\n",
       " 713: 'come',\n",
       " 714: 'bus',\n",
       " 715: 'atención',\n",
       " 716: 'acabo',\n",
       " 717: 'abogado',\n",
       " 718: 'taza',\n",
       " 719: 'siete',\n",
       " 720: 'pareces',\n",
       " 721: 'mía',\n",
       " 722: 'mira',\n",
       " 723: 'lluvia',\n",
       " 724: 'inteligente',\n",
       " 725: 'estúpido',\n",
       " 726: 'conseguir',\n",
       " 727: 'completamente',\n",
       " 728: 'rompió',\n",
       " 729: 'radio',\n",
       " 730: 'cuántas',\n",
       " 731: 'caso',\n",
       " 732: 'acaba',\n",
       " 733: 'abuelo',\n",
       " 734: 'vaso',\n",
       " 735: 'sitio',\n",
       " 736: 'sigue',\n",
       " 737: 'peso',\n",
       " 738: 'peligro',\n",
       " 739: 'habría',\n",
       " 740: 'papá',\n",
       " 741: 'ocurrió',\n",
       " 742: 'llamar',\n",
       " 743: 'dirección',\n",
       " 744: 'cuesta',\n",
       " 745: 'cuchillo',\n",
       " 746: 'aconsejó',\n",
       " 747: 'tenés',\n",
       " 748: 'situación',\n",
       " 749: 'pagar',\n",
       " 750: 'opinión',\n",
       " 751: 'llevar',\n",
       " 752: 'invierno',\n",
       " 753: 'ganar',\n",
       " 754: 'esas',\n",
       " 755: 'entró',\n",
       " 756: 'ello',\n",
       " 757: 'digas',\n",
       " 758: 'deberes',\n",
       " 759: 'cine',\n",
       " 760: 'blanco',\n",
       " 761: 'barco',\n",
       " 762: 'almuerzo',\n",
       " 763: 'londres',\n",
       " 764: 'jugando',\n",
       " 765: 'causa',\n",
       " 766: 'casado',\n",
       " 767: 'vale',\n",
       " 768: 'rato',\n",
       " 769: 'oí',\n",
       " 770: 'montaña',\n",
       " 771: 'estáis',\n",
       " 772: 'dijiste',\n",
       " 773: 'decirle',\n",
       " 774: 'comido',\n",
       " 775: 'ayudarte',\n",
       " 776: 'atrás',\n",
       " 777: 'aire',\n",
       " 778: 'saben',\n",
       " 779: 'medio',\n",
       " 780: 'finalmente',\n",
       " 781: 'final',\n",
       " 782: 'carro',\n",
       " 783: 'viven',\n",
       " 784: 'toma',\n",
       " 785: 'suficientemente',\n",
       " 786: 'siendo',\n",
       " 787: 'sentido',\n",
       " 788: 'pieza',\n",
       " 789: 'ocupada',\n",
       " 790: 'ocho',\n",
       " 791: 'miró',\n",
       " 792: 'meses',\n",
       " 793: 'chicos',\n",
       " 794: 'último',\n",
       " 795: 'siguió',\n",
       " 796: 'sentó',\n",
       " 797: 'llevaba',\n",
       " 798: 'dime',\n",
       " 799: 'terminó',\n",
       " 800: 'playa',\n",
       " 801: 'partido',\n",
       " 802: 'paraguas',\n",
       " 803: 'morir',\n",
       " 804: 'llegué',\n",
       " 805: 'llamó',\n",
       " 806: 'jefe',\n",
       " 807: 'huevos',\n",
       " 808: 'hubo',\n",
       " 809: 'grandes',\n",
       " 810: 'desearía',\n",
       " 811: 'sal',\n",
       " 812: 'responder',\n",
       " 813: 'respecto',\n",
       " 814: 'pan',\n",
       " 815: 'imposible',\n",
       " 816: 'corriendo',\n",
       " 817: 'aeropuerto',\n",
       " 818: 'silla',\n",
       " 819: 'pasada',\n",
       " 820: 'mamá',\n",
       " 821: 'irme',\n",
       " 822: 'intentando',\n",
       " 823: 'haz',\n",
       " 824: 'duele',\n",
       " 825: 'diga',\n",
       " 826: 'corazón',\n",
       " 827: 'confiar',\n",
       " 828: 'clima',\n",
       " 829: 'cambiar',\n",
       " 830: 'voz',\n",
       " 831: 'trató',\n",
       " 832: 'sala',\n",
       " 833: 'quedarme',\n",
       " 834: 'pescado',\n",
       " 835: 'peligroso',\n",
       " 836: 'paciente',\n",
       " 837: 'manzana',\n",
       " 838: 'funciona',\n",
       " 839: 'divertido',\n",
       " 840: 'viste',\n",
       " 841: 'triste',\n",
       " 842: 'semanas',\n",
       " 843: 'reglas',\n",
       " 844: 'probablemente',\n",
       " 845: 'pena',\n",
       " 846: 'papel',\n",
       " 847: 'normalmente',\n",
       " 848: 'manzanas',\n",
       " 849: 'hermosa',\n",
       " 850: 'escritorio',\n",
       " 851: 'dile',\n",
       " 852: 'correcto',\n",
       " 853: 'conoces',\n",
       " 854: 'venido',\n",
       " 855: 'trata',\n",
       " 856: 'torta',\n",
       " 857: 'minuto',\n",
       " 858: 'irse',\n",
       " 859: 'intentó',\n",
       " 860: 'hablo',\n",
       " 861: 'derecho',\n",
       " 862: 'ayudó',\n",
       " 863: 'afuera',\n",
       " 864: 'simplemente',\n",
       " 865: 'sale',\n",
       " 866: 'lleno',\n",
       " 867: 'lamento',\n",
       " 868: 'hiciera',\n",
       " 869: 'hermanos',\n",
       " 870: 'haces',\n",
       " 871: 'estés',\n",
       " 872: 'dicen',\n",
       " 873: 'comiendo',\n",
       " 874: 'ambos',\n",
       " 875: 'viendo',\n",
       " 876: 'vayas',\n",
       " 877: 'taxi',\n",
       " 878: 'supongo',\n",
       " 879: 'rojo',\n",
       " 880: 'pueblo',\n",
       " 881: 'poner',\n",
       " 882: 'ninguno',\n",
       " 883: 'nació',\n",
       " 884: 'mayoría',\n",
       " 885: 'iglesia',\n",
       " 886: 'fotos',\n",
       " 887: 'dejes',\n",
       " 888: 'alta',\n",
       " 889: 'tierra',\n",
       " 890: 'significa',\n",
       " 891: 'seguir',\n",
       " 892: 'quiera',\n",
       " 893: 'quedarse',\n",
       " 894: 'parís',\n",
       " 895: 'mirando',\n",
       " 896: 'llaves',\n",
       " 897: 'lago',\n",
       " 898: 'favorita',\n",
       " 899: 'cocinar',\n",
       " 900: 'cielo',\n",
       " 901: 'viajar',\n",
       " 902: 'verme',\n",
       " 903: 'suelo',\n",
       " 904: 'resolver',\n",
       " 905: 'próxima',\n",
       " 906: 'piso',\n",
       " 907: 'novio',\n",
       " 908: 'mensaje',\n",
       " 909: 'mar',\n",
       " 910: 'estaría',\n",
       " 911: 'empezar',\n",
       " 912: 'domingo',\n",
       " 913: 'boca',\n",
       " 914: 'amo',\n",
       " 915: 'traje',\n",
       " 916: 'serio',\n",
       " 917: 'sacó',\n",
       " 918: 'quedé',\n",
       " 919: 'pensó',\n",
       " 920: 'noticias',\n",
       " 921: 'negro',\n",
       " 922: 'necesario',\n",
       " 923: 'habló',\n",
       " 924: 'escribió',\n",
       " 925: 'diciendo',\n",
       " 926: 'desayuno',\n",
       " 927: 'contento',\n",
       " 928: 'comprado',\n",
       " 929: 'buenas',\n",
       " 930: 'abierta',\n",
       " 931: 'varias',\n",
       " 932: 'podés',\n",
       " 933: 'olvidó',\n",
       " 934: 'necesitaba',\n",
       " 935: 'iré',\n",
       " 936: 'incluso',\n",
       " 937: 'futuro',\n",
       " 938: 'francia',\n",
       " 939: 'empleo',\n",
       " 940: 'domingos',\n",
       " 941: 'demás',\n",
       " 942: 'decirme',\n",
       " 943: 'caliente',\n",
       " 944: 'caballo',\n",
       " 945: 'ayudarme',\n",
       " 946: 'prisa',\n",
       " 947: 'gustaba',\n",
       " 948: 'fuimos',\n",
       " 949: 'felices',\n",
       " 950: 'dios',\n",
       " 951: 'contó',\n",
       " 952: 'cita',\n",
       " 953: 'buenos',\n",
       " 954: 'brazo',\n",
       " 955: 'anciano',\n",
       " 956: 'amable',\n",
       " 957: 'abrió',\n",
       " 958: 'abrigo',\n",
       " 959: 'york',\n",
       " 960: 'pobre',\n",
       " 961: 'periódico',\n",
       " 962: 'pase',\n",
       " 963: 'llegado',\n",
       " 964: 'entiende',\n",
       " 965: 'comenzó',\n",
       " 966: 'bailar',\n",
       " 967: 'vosotros',\n",
       " 968: 'presidente',\n",
       " 969: 'pared',\n",
       " 970: 'mil',\n",
       " 971: 'matar',\n",
       " 972: 'hicieron',\n",
       " 973: 'helado',\n",
       " 974: 'daño',\n",
       " 975: 'cartas',\n",
       " 976: 'ama',\n",
       " 977: 'abrir',\n",
       " 978: 'vuelve',\n",
       " 979: 'tratando',\n",
       " 980: 'siguiente',\n",
       " 981: 'siente',\n",
       " 982: 'prueba',\n",
       " 983: 'llevó',\n",
       " 984: 'leído',\n",
       " 985: 'estábamos',\n",
       " 986: 'escrito',\n",
       " 987: 'diferente',\n",
       " 988: 'dejé',\n",
       " 989: 'casó',\n",
       " 990: 'aunque',\n",
       " 991: 'aquella',\n",
       " 992: 'amiga',\n",
       " 993: 'adónde',\n",
       " 994: 'tarta',\n",
       " 995: 'preocupado',\n",
       " 996: 'noticia',\n",
       " 997: 'mantener',\n",
       " 998: 'llegue',\n",
       " 999: 'lentes',\n",
       " ...}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_index = {i:word for i,word in enumerate(target_vocab)}\n",
    "target_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52ca584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to vectorize the source and target sentences and to prepare the final dataset\n",
    "\n",
    "def vectorize_dataset(source, target):\n",
    "    source = source_vectorizer(source)\n",
    "    target = target_vectorizer(target)\n",
    "    return ({\n",
    "        \"encoder_inputs\": source,\n",
    "        \"decoder_inputs\": target[:, :-1],  # Exclude the last token for decoder input\n",
    "    }, target[:, 1:])  # Shift by one for the target output\n",
    "\n",
    "def make_dataset(data):\n",
    "    dataset = data.batch(BATCH_SIZE) # batches the data\n",
    "    dataset = dataset.map(vectorize_dataset, num_parallel_calls=4)\n",
    "    \n",
    "    return dataset.shuffle(2048).prefetch(16).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3da93a",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"./images/rnn_ed.jpg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b69ed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_inputs shape: (64, 20)\n",
      "decoder_inputs shape: (64, 20)\n",
      "targets shape: (64, 20)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the final vectorized data \n",
    "#..which basically takes the sequences of words for each language and converts them into integers\n",
    "\n",
    "train_int = make_dataset(train_data)\n",
    "val_int = make_dataset(val_data)\n",
    "test_int = make_dataset(test_data)\n",
    "\n",
    "# Display a sample\n",
    "for inputs, targets in train_int.take(1):\n",
    "    print(f\"encoder_inputs shape: {inputs['encoder_inputs'].shape}\")\n",
    "    print(f\"decoder_inputs shape: {inputs['decoder_inputs'].shape}\")\n",
    "    print(f\"targets shape: {targets.shape}\")\n",
    "\n",
    "# because of vectorization, the original dataset, where each element was a sentence pair (english,spanish) is now \n",
    "# batches of data, with 64samples in each batch. \n",
    "# each sample is a tuple where first element is a dict of inputs, second element is targets\n",
    "# sequence length for inputs and targets is 20. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e8a1693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: {'encoder_inputs': <tf.Tensor: shape=(64, 20), dtype=int64, numpy=\n",
      "array([[ 550,   12, 1585, ...,    0,    0,    0],\n",
      "       [  23,   15,    5, ...,    0,    0,    0],\n",
      "       [  46,    7, 7529, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  28, 1024,    8, ...,    0,    0,    0],\n",
      "       [ 141,   33,  597, ...,    0,    0,    0],\n",
      "       [2978,    8,    7, ...,    0,    0,    0]], dtype=int64)>, 'decoder_inputs': <tf.Tensor: shape=(64, 20), dtype=int64, numpy=\n",
      "array([[   2,   93,   12, ...,    0,    0,    0],\n",
      "       [   2,   27, 1242, ...,    0,    0,    0],\n",
      "       [   2,   12,   18, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   2,   36, 1593, ...,    0,    0,    0],\n",
      "       [   2,   39,    7, ...,    0,    0,    0],\n",
      "       [   2,   10, 7617, ...,    0,    0,    0]], dtype=int64)>} \n",
      "\n",
      "Targets: tf.Tensor(\n",
      "[  93   12  114  483   62 4521   24    9    5   28  255   11   10 1244\n",
      " 3443    3    0    0    0    0], shape=(20,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_int.take(1):\n",
    "    print (\"Inputs:\", inputs, \"\\n\")\n",
    "    print (\"Targets:\",targets[0])\n",
    "\n",
    "# As you see decoder_inputs is nothing but target sequence beginning with token [start] (index=2)\n",
    "# targets is also the target sequence but offset by one token and \n",
    "#...begins with element next to [start] token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d273acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Inputs: tf.Tensor(\n",
      "[  2 300 167 343   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0], shape=(20,), dtype=int64)\n",
      "Decoder Inputs: tf.Tensor(\n",
      "[   2   10  714 2798  334    3    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0], shape=(20,), dtype=int64)\n",
      "Targets: tf.Tensor(\n",
      "[  10  714 2798  334    3    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0], shape=(20,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_int.take(1):\n",
    "    print (\"Encoder Inputs:\", inputs['encoder_inputs'][0])\n",
    "    print (\"Decoder Inputs:\",inputs['decoder_inputs'][0])\n",
    "    print (\"Targets:\",targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71ead1b",
   "metadata": {},
   "source": [
    "### Build a GRU based encoder-decoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d21088",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"./images/rnn_ed.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64fb561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b7b27f",
   "metadata": {},
   "source": [
    "**Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29e77b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an encoder, which takes an input source sentence, and \n",
    "#..encodes it as vector with HIDDEN_DIM units.\n",
    "\n",
    "# Basically it will capture the essense of the sentence.\n",
    "\n",
    "# Input shape for encoder\n",
    "source = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "\n",
    "# Embedding Layer\n",
    "x = layers.Embedding(VOCAB_SIZE, EMBED_DIM, mask_zero=True)(source)\n",
    "\n",
    "# Bidirectional GRU Layer\n",
    "encoded_source = layers.Bidirectional(layers.GRU(HIDDEN_DIM), merge_mode=\"sum\")(x)\n",
    "\n",
    "# Default return_sequences=False in the below Bidirectional GRU layer, \n",
    "#...meaning only the output at the final step will be taken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec2fd93",
   "metadata": {},
   "source": [
    "**Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0dde1006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape for decoder\n",
    "targets_previous_tokens = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\") \n",
    "# these tokens are offset by 1 step. so model will only see previous token, \n",
    "#...and tries to predict next token\n",
    "\n",
    "# Embedding Layer\n",
    "x = layers.Embedding(VOCAB_SIZE, EMBED_DIM, mask_zero=True)(targets_previous_tokens)\n",
    "\n",
    "# GRU layer\n",
    "x = layers.GRU(HIDDEN_DIM, return_sequences=True)(x, initial_state=encoded_source) # encoded source\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Output dense layer\n",
    "targets_next_tokens = layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e695468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 256)    3840000     ['encoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 256)    3840000     ['decoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 1024)         7876608     ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, None, 1024)   3938304     ['embedding_1[0][0]',            \n",
      "                                                                  'bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, None, 1024)   0           ['gru_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 15000)  15375000    ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34,869,912\n",
      "Trainable params: 34,869,912\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the Encoder - Decoder Model\n",
    "\n",
    "model_gru_encoder_decoder = keras.Model([source, targets_previous_tokens], targets_next_tokens)\n",
    "model_gru_encoder_decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc21e39b",
   "metadata": {},
   "source": [
    "### Compile & Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "840102b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"./models/model_gru_encoder_decoder_ensp.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "080b2b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will reuse this function to train and evaluate for convenience\n",
    "def train_evaluate(model,path,train,val,test):\n",
    "    \n",
    "    # call backs\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = path,\n",
    "                                                       save_best_only=True) # Save only best model\n",
    "    \n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, \n",
    "                                                 restore_best_weights=True)\n",
    "    callbacks = [checkpoint_cb, earlystop_cb]\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\",  metrics = [\"accuracy\"])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(train, validation_data = val, callbacks = callbacks, epochs=50)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(test)\n",
    "    \n",
    "    return (history,test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e061d2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1302/1302 [==============================] - 140s 91ms/step - loss: 1.6430 - accuracy: 0.4147 - val_loss: 1.3519 - val_accuracy: 0.4941\n",
      "Epoch 2/50\n",
      "1302/1302 [==============================] - 110s 84ms/step - loss: 1.3189 - accuracy: 0.5254 - val_loss: 1.1632 - val_accuracy: 0.5636\n",
      "Epoch 3/50\n",
      "1302/1302 [==============================] - 108s 83ms/step - loss: 1.1756 - accuracy: 0.5750 - val_loss: 1.0792 - val_accuracy: 0.5979\n",
      "Epoch 4/50\n",
      "1302/1302 [==============================] - 108s 83ms/step - loss: 1.0829 - accuracy: 0.6074 - val_loss: 1.0417 - val_accuracy: 0.6188\n",
      "Epoch 5/50\n",
      "1302/1302 [==============================] - 108s 83ms/step - loss: 1.0351 - accuracy: 0.6322 - val_loss: 1.0273 - val_accuracy: 0.6288\n",
      "Epoch 6/50\n",
      "1302/1302 [==============================] - 93s 71ms/step - loss: 1.0036 - accuracy: 0.6511 - val_loss: 1.0243 - val_accuracy: 0.6353\n",
      "Epoch 7/50\n",
      "1302/1302 [==============================] - 86s 66ms/step - loss: 0.9831 - accuracy: 0.6653 - val_loss: 1.0240 - val_accuracy: 0.6382\n",
      "Epoch 8/50\n",
      "1302/1302 [==============================] - 77s 59ms/step - loss: 0.9692 - accuracy: 0.6752 - val_loss: 1.0256 - val_accuracy: 0.6397\n",
      "Epoch 9/50\n",
      "1302/1302 [==============================] - 82s 63ms/step - loss: 0.9583 - accuracy: 0.6841 - val_loss: 1.0319 - val_accuracy: 0.6409\n",
      "Epoch 10/50\n",
      "1302/1302 [==============================] - 80s 61ms/step - loss: 0.9511 - accuracy: 0.6897 - val_loss: 1.0312 - val_accuracy: 0.6424\n",
      "Epoch 11/50\n",
      "1302/1302 [==============================] - 80s 61ms/step - loss: 0.9453 - accuracy: 0.6942 - val_loss: 1.0347 - val_accuracy: 0.6421\n",
      "Epoch 12/50\n",
      "1302/1302 [==============================] - 80s 61ms/step - loss: 0.9417 - accuracy: 0.6971 - val_loss: 1.0410 - val_accuracy: 0.6423\n",
      "279/279 [==============================] - 12s 26ms/step - loss: 1.0191 - accuracy: 0.6389\n"
     ]
    }
   ],
   "source": [
    "(history_gru,test_accuracy_gru) = train_evaluate(model_gru_encoder_decoder,path,\n",
    "                                               train_int,\n",
    "                                               val_int,\n",
    "                                               test_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0caca566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test data set is 0.6389417052268982\n"
     ]
    }
   ],
   "source": [
    "print (f\"Accuracy on the test data set is {test_accuracy_gru}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50a78ca",
   "metadata": {},
   "source": [
    "### Inference: Translate Few sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84482611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "tf.Tensor(b\"We'll soon find out.\", shape=(), dtype=string)\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "[start] nos [UNK] pronto [end]\n",
      "\n",
      "\n",
      "tf.Tensor(b'Tom and Mary agreed to leave the party before midnight.', shape=(), dtype=string)\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[start] tom y mary [UNK] a que [UNK] a la fiesta antes de las [UNK] [end]\n",
      "\n",
      "\n",
      "tf.Tensor(b'He must be an honest man.', shape=(), dtype=string)\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "[start] Él debe ser un hombre [UNK] [end]\n",
      "\n",
      "\n",
      "tf.Tensor(b'It is time you went to school.', shape=(), dtype=string)\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "[start] es hora de que la escuela [end]\n",
      "\n",
      "\n",
      "tf.Tensor(b\"Tom can't be reasoned with.\", shape=(), dtype=string)\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "[start] tom no puede ser con nosotros [end]\n",
      "\n",
      "\n",
      "tf.Tensor(b'Can you tell me your address?', shape=(), dtype=string)\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "[start] puedes decirme tu dirección [end]\n",
      "\n",
      "\n",
      "tf.Tensor(b\"He's hopelessly in love.\", shape=(), dtype=string)\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "[start] Él está [UNK] [UNK] [end]\n",
      "\n",
      "\n",
      "tf.Tensor(b'He must be an honest man.', shape=(), dtype=string)\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "[start] Él debe ser un hombre [UNK] [end]\n",
      "\n",
      "\n",
      "tf.Tensor(b'Tom bought a used Toyota.', shape=(), dtype=string)\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "[start] tom compró un [UNK] [end]\n",
      "\n",
      "\n",
      "tf.Tensor(b'What do you really think of him?', shape=(), dtype=string)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "[start] qué de verdad le hace [end]\n",
      "\n",
      "\n",
      "tf.Tensor(b'Mary is speaking to strangers.', shape=(), dtype=string)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "[start] mary está hablando con nadie [end]\n",
      "\n",
      "\n",
      "tf.Tensor(b'I am a teacher of English.', shape=(), dtype=string)\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "[start] soy profesor de inglés [end]\n",
      "\n",
      "\n",
      "tf.Tensor(b\"He's hopelessly in love.\", shape=(), dtype=string)\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "[start] Él está [UNK] [UNK] [end]\n",
      "\n",
      "\n",
      "tf.Tensor(b'Tom and Mary agreed to leave the party before midnight.', shape=(), dtype=string)\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "[start] tom y mary [UNK] a que [UNK] a la fiesta antes de las [UNK] [end]\n",
      "\n",
      "\n",
      "tf.Tensor(b'Tom bought a used Toyota.', shape=(), dtype=string)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "[start] tom compró un [UNK] [end]\n",
      "\n",
      "\n",
      "tf.Tensor(b'Tom and Mary agreed to leave the party before midnight.', shape=(), dtype=string)\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "[start] tom y mary [UNK] a que [UNK] a la fiesta antes de las [UNK] [end]\n",
      "\n",
      "\n",
      "tf.Tensor(b\"Tom can't be reasoned with.\", shape=(), dtype=string)\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "[start] tom no puede ser con nosotros [end]\n",
      "\n",
      "\n",
      "tf.Tensor(b'What do you really think of him?', shape=(), dtype=string)\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "[start] qué de verdad le hace [end]\n",
      "\n",
      "\n",
      "tf.Tensor(b\"You don't need to answer that letter.\", shape=(), dtype=string)\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "[start] no tienes que tomar esa carta [end]\n",
      "\n",
      "\n",
      "tf.Tensor(b'It is time you went to school.', shape=(), dtype=string)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "[start] es hora de que la escuela [end]\n"
     ]
    }
   ],
   "source": [
    "def translate_sequence(input_sentence):\n",
    "    vectorized_input_sentence = source_vectorizer([input_sentence]) # Vectorize input source sequence\n",
    "    target_sentence = \"[start]\"\n",
    "    \n",
    "    for i in range(MAX_SEQ_LEN):\n",
    "        \n",
    "        # Vectorize target\n",
    "        vectorized_target_sentence = target_vectorizer([target_sentence]) \n",
    "               \n",
    "        # Apply model on the list of [input sentence, target sentence predicted so far]\n",
    "        next_token_predictions = model_gru_encoder_decoder.predict(\n",
    "            [vectorized_input_sentence, vectorized_target_sentence])\n",
    "        \n",
    "        # Index with high probability\n",
    "        sampled_token_index = np.argmax(next_token_predictions[0, i, :]) \n",
    "        \n",
    "        # look up in target vocabulary index dictionary\n",
    "        sampled_token = target_index[sampled_token_index] \n",
    "        \n",
    "        # Add the newly predicted token to the target sentence\n",
    "        target_sentence += \" \" + sampled_token\n",
    "        \n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "            \n",
    "    return target_sentence\n",
    "\n",
    "\n",
    "# Test on some sample raw test sentences\n",
    "source_sentences = [en for en,sp in test_data.take(20)]\n",
    "\n",
    "for _ in range(20):\n",
    "    input_sentence = random.choice(source_sentences)\n",
    "    print(\"\\n\")\n",
    "    print(input_sentence)\n",
    "    print(translate_sequence(input_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcde67c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
